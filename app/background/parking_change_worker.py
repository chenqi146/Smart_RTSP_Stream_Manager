"""è½¦ä½å˜åŒ–æ£€æµ‹ Worker

ç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼Œç”¨äºå¼‚æ­¥æ‰§è¡Œï¼š
- ä» screenshots è¡¨ä¸­è¯»å– yolo_status = 'pending' çš„æˆªå›¾ï¼›
- è°ƒç”¨ YOLOv8 æ£€æµ‹è½¦è¾†ï¼›
- æŒ‰è½¦ä½åæ ‡è®¡ç®—æ¯ä¸ªè½¦ä½å½“å‰æ˜¯å¦æœ‰è½¦ï¼›
- ä¸å†å²è®°å½•å¯¹æ¯”ï¼Œå†™å…¥ parking_changes / parking_change_snapshotsï¼›
- æ›´æ–° screenshots.yolo_status å’Œ yolo_last_errorã€‚
"""

from __future__ import annotations

import sys
import time
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime

from sqlalchemy import desc

# å…¼å®¹ä»é¡¹ç›®æ ¹ç›®å½•ç›´æ¥è¿è¡Œæˆ–ä» app.main å¯¼å…¥
ROOT = Path(__file__).resolve().parents[2]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from db import SessionLocal  # noqa: E402
from models import (  # noqa: E402
    Screenshot,
    Task,
    NvrConfig,
    ChannelConfig,
    ParkingSpace,
    ParkingChange,
    ParkingChangeSnapshot,
)
from app.core.config import (  # noqa: E402
    SCREENSHOT_BASE,
    VEHICLE_SIMILARITY_THRESHOLD_SAME_DAY,
    VEHICLE_SIMILARITY_THRESHOLD_CROSS_DAY,
    VEHICLE_SIMILARITY_THRESHOLD_SHORT_INTERVAL,
    SHORT_INTERVAL_SECONDS,
    BRIGHTNESS_LOW_THRESHOLD,
    BRIGHTNESS_HIGH_THRESHOLD,
    CLARITY_THRESHOLD,
    HIGH_ROBUSTNESS_MODE_ENABLED,
    MAX_CONSECUTIVE_MISS_DETECTIONS,
    TIME_PERIOD_EARLY_MORNING,
    TIME_PERIOD_DAYTIME,
    TIME_PERIOD_EVENING,
    TIME_PERIOD_NIGHT,
    MIN_SPACE_MATCH_CONFIDENCE_DAY,
    MIN_SPACE_MATCH_CONFIDENCE_NIGHT,
    TIME_PERIOD_THRESHOLD_FACTOR_EARLY_MORNING,
    TIME_PERIOD_THRESHOLD_FACTOR_DAYTIME,
    TIME_PERIOD_THRESHOLD_FACTOR_EVENING,
    TIME_PERIOD_THRESHOLD_FACTOR_NIGHT,
    BRIGHTNESS_THRESHOLD_FACTOR_DARK,
    BRIGHTNESS_THRESHOLD_FACTOR_VERY_DARK,
    CLARITY_THRESHOLD_FACTOR_LOW,
    WEATHER_THRESHOLD_FACTOR_RAINY,
    WEATHER_THRESHOLD_FACTOR_FOGGY,
    WEATHER_THRESHOLD_FACTOR_CLOUDY,
    WEATHER_THRESHOLD_FACTOR_SUNNY,
    MIN_YOLO_CONFIDENCE_FOR_CHANGE_DETECTION,
    STATE_CONTINUATION_PROTECTION_ENABLED,
    STATE_CONTINUATION_TIME_THRESHOLD,
    STATE_CONTINUATION_POSITION_THRESHOLD,
    STATE_CONTINUATION_SIMILARITY_MARGIN,
    STATE_LOCK_ENABLED,
    STATE_LOCK_FRAMES,
    STATE_UNLOCK_FRAMES,
)
from services.yolo_detector import detect_cars_in_region, detect_cars_on_image, extract_vehicle_features, preload_model  # noqa: E402
import json
import cv2
import numpy as np
from datetime import datetime, timedelta


def _bbox_intersection_area(a: Tuple[int, int, int, int], b: Tuple[int, int, int, int]) -> int:
    """è®¡ç®—ä¸¤ä¸ªçŸ©å½¢æ¡†çš„äº¤é›†é¢ç§¯ã€‚"""
    ax1, ay1, ax2, ay2 = a
    bx1, by1, bx2, by2 = b
    ix1 = max(ax1, bx1)
    iy1 = max(ay1, by1)
    ix2 = min(ax2, bx2)
    iy2 = min(ay2, by2)
    if ix2 <= ix1 or iy2 <= iy1:
        return 0
    return (ix2 - ix1) * (iy2 - iy1)


def _parse_track_space(track_space_str: str) -> Tuple[int, int, int, int] | None:
    """è§£æè·Ÿè¸ªåŒºåŸŸåæ ‡å­—ç¬¦ä¸²ã€‚
    
    æ”¯æŒæ ¼å¼ï¼š
    - JSONæ•°ç»„å­—ç¬¦ä¸²: "[x1, y1, x2, y2]"
    - å­—å…¸å­—ç¬¦ä¸²: '{"x1": 10, "y1": 20, "x2": 100, "y2": 200}'
    
    è¿”å›: (x1, y1, x2, y2) æˆ– None
    """
    if not track_space_str or not track_space_str.strip():
        return None
    
    try:
        # å°è¯•è§£æJSON
        parsed = json.loads(track_space_str.strip())
        
        if isinstance(parsed, list) and len(parsed) >= 4:
            # æ ¼å¼: [x1, y1, x2, y2]
            return (int(parsed[0]), int(parsed[1]), int(parsed[2]), int(parsed[3]))
        elif isinstance(parsed, dict):
            # æ ¼å¼: {"x1": ..., "y1": ..., "x2": ..., "y2": ...}
            if all(k in parsed for k in ["x1", "y1", "x2", "y2"]):
                return (int(parsed["x1"]), int(parsed["y1"]), int(parsed["x2"]), int(parsed["y2"]))
    except (json.JSONDecodeError, ValueError, KeyError):
        pass
    
    return None


def _calculate_iou(box1: Tuple[int, int, int, int], box2: Tuple[int, int, int, int]) -> float:
    """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoUï¼ˆIntersection over Unionï¼‰ã€‚
    
    å‚æ•°:
        box1: (x1, y1, x2, y2) æ ¼å¼
        box2: (x1, y1, x2, y2) æ ¼å¼
    
    è¿”å›:
        IoUå€¼ï¼ˆ0.0-1.0ï¼‰
    """
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    
    # è®¡ç®—äº¤é›†
    x1_i = max(x1_1, x1_2)
    y1_i = max(y1_1, y1_2)
    x2_i = min(x2_1, x2_2)
    y2_i = min(y2_1, y2_2)
    
    if x2_i <= x1_i or y2_i <= y1_i:
        return 0.0
    
    intersection = (x2_i - x1_i) * (y2_i - y1_i)
    
    # è®¡ç®—å¹¶é›†
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union = area1 + area2 - intersection
    
    if union == 0:
        return 0.0
    
    return intersection / union


def _detect_space_occupancy(
    image_path: Path,
    spaces: List[ParkingSpace],
    track_space_str: str | None = None,
    overlap_threshold: float = 0.3,
    extract_features: bool = True,
    image_brightness: float = None,  # å›¾åƒäº®åº¦ï¼Œç”¨äºåŠ¨æ€è°ƒæ•´æ£€æµ‹å‚æ•°
) -> Tuple[Dict[int, bool], Dict[int, Tuple[int, int, int, int]], Dict[int, float], Dict[int, Dict[str, Any]]]:
    """å¯¹æ¯ä¸ªè½¦ä½åæ ‡åŒºåŸŸè¿›è¡Œ YOLO æ£€æµ‹ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰è½¦è¾†ã€‚

    é‡‡ç”¨æ–°çš„ç­–ç•¥ï¼šæ•´å¼ å›¾æ£€æµ‹ + åæ ‡åŒ¹é…
    1. åœ¨æ•´å¼ å›¾ä¸Šè¿›è¡ŒYOLOæ£€æµ‹ï¼ˆé¿å…ROIè£å‰ªå¯¼è‡´çš„åæ ‡é”™ä½å’Œç»†èŠ‚ä¸¢å¤±ï¼‰
    2. è®¡ç®—æ¯ä¸ªæ£€æµ‹æ¡†ä¸è½¦ä½åŒºåŸŸçš„IoUï¼Œåˆ¤æ–­è½¦è¾†æ˜¯å¦åœ¨è½¦ä½å†…
    3. å¦‚æœIoU >= overlap_thresholdï¼Œåˆ™è®¤ä¸ºè½¦ä½æœ‰è½¦

    æ³¨æ„ï¼š
    - å½“å‰é¡¹ç›®ä¸­ ParkingSpace.bbox_x1 / bbox_y1 / bbox_x2 / bbox_y2 å®é™…å«ä¹‰æ˜¯ï¼š
      bbox_x1 = xï¼ˆå·¦ä¸Šè§’Xï¼‰
      bbox_y1 = yï¼ˆå·¦ä¸Šè§’Yï¼‰
      bbox_x2 = widthï¼ˆå®½åº¦ï¼‰
      bbox_y2 = heightï¼ˆé«˜åº¦ï¼‰
      å³ [x, y, width, height]ï¼Œè€Œä¸æ˜¯ [x1, y1, x2, y2]ã€‚
    - YOLOè¿”å›çš„åæ ‡å·²ç»æ˜¯ç›¸å¯¹äºåŸå§‹å›¾åƒçš„ï¼Œæ— éœ€åæ ‡æ˜ å°„ã€‚

    è¿”å›:
        (å ç”¨çŠ¶æ€å­—å…¸, æ£€æµ‹åŒºåŸŸå­—å…¸, ç½®ä¿¡åº¦å­—å…¸, ç‰¹å¾å­—å…¸)
        - å ç”¨çŠ¶æ€å­—å…¸: {space_id: bool} - æ¯ä¸ªè½¦ä½æ˜¯å¦æœ‰è½¦
        - æ£€æµ‹åŒºåŸŸå­—å…¸: {space_id: (x, y, w, h)} - æ¯ä¸ªè½¦ä½å®é™…æ£€æµ‹çš„åŒºåŸŸåæ ‡
        - ç½®ä¿¡åº¦å­—å…¸: {space_id: float} - æ¯ä¸ªè½¦ä½æ£€æµ‹çš„ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰
        - ç‰¹å¾å­—å…¸: {space_id: Dict} - æ¯ä¸ªè½¦ä½çš„è½¦è¾†ç‰¹å¾ï¼ˆå¦‚æœæœ‰è½¦ï¼‰
    """
    result: Dict[int, bool] = {}
    detection_regions: Dict[int, Tuple[int, int, int, int]] = {}
    confidence_map: Dict[int, float] = {}
    features_map: Dict[int, Dict[str, Any]] = {}
    
    # è¯»å–åŸå§‹å›¾åƒï¼ˆç”¨äºç‰¹å¾æå–ï¼‰
    import cv2
    img = cv2.imread(str(image_path))
    if img is None:
        print(f"[ParkingChangeWorker] è­¦å‘Š: æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        for space in spaces:
            result[space.id] = False
            confidence_map[space.id] = 0.0
            x = int(space.bbox_x1)
            y = int(space.bbox_y1)
            w = max(1, int(space.bbox_x2))
            h = max(1, int(space.bbox_y2))
            detection_regions[space.id] = (x, y, w, h)
        return result, detection_regions, confidence_map, features_map
    
    img_height, img_width = img.shape[:2]
    
    # åœ¨æ•´å¼ å›¾ä¸Šè¿›è¡ŒYOLOæ£€æµ‹
    print(f"[ParkingChangeWorker] ä½¿ç”¨æ•´å›¾æ£€æµ‹+åæ ‡åŒ¹é…ç­–ç•¥ï¼ˆå›¾åƒå°ºå¯¸: {img_width}x{img_height}ï¼‰")
    car_boxes, preprocess_info = detect_cars_on_image(
        image_path,
        image_brightness=image_brightness,
    )
    
    print(f"[ParkingChangeWorker] æ•´å›¾æ£€æµ‹åˆ° {len(car_boxes)} ä¸ªè½¦è¾†å¯¹è±¡")
    
    # å¯¹æ¯ä¸ªè½¦ä½ï¼Œè®¡ç®—ä¸æ£€æµ‹æ¡†çš„IoU
    for space in spaces:
        # è½¦ä½åæ ‡æ ¼å¼ï¼š[x, y, width, height]
        x = int(space.bbox_x1)
        y = int(space.bbox_y1)
        w = max(1, int(space.bbox_x2))
        h = max(1, int(space.bbox_y2))
        
        # è½¬æ¢ä¸º (x1, y1, x2, y2) æ ¼å¼ç”¨äºIoUè®¡ç®—
        space_box = (x, y, x + w, y + h)
        
        # æŸ¥æ‰¾ä¸è¯¥è½¦ä½IoUæœ€å¤§çš„è½¦è¾†æ£€æµ‹æ¡†
        best_iou = 0.0
        best_confidence = 0.0
        best_car_box = None
        
        for car_box in car_boxes:
            car_box_xyxy = (car_box["x1"], car_box["y1"], car_box["x2"], car_box["y2"])
            iou = _calculate_iou(space_box, car_box_xyxy)
            
            if iou > best_iou:
                best_iou = iou
                best_confidence = car_box["confidence"]
                best_car_box = car_box
                print(f"[ParkingChangeWorker] è½¦ä½ {space.space_name}: æ‰¾åˆ°åŒ¹é…è½¦è¾† (IoU={iou:.3f}, ç½®ä¿¡åº¦={best_confidence:.3f}, è½¦è¾†åæ ‡=({car_box['x1']},{car_box['y1']})-({car_box['x2']},{car_box['y2']}))")
        
        # ç¡®å®šæœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆæ ¹æ®ç¯å¢ƒï¼šç™½å¤©/å¤œé—´ï¼‰
        min_confidence_threshold = MIN_SPACE_MATCH_CONFIDENCE_DAY
        if image_brightness is not None and image_brightness < 120:
            min_confidence_threshold = MIN_SPACE_MATCH_CONFIDENCE_NIGHT
        
        # å¦‚æœIoU >= overlap_threshold ä¸”ç½®ä¿¡åº¦ >= æœ€ä½é˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºè½¦ä½æœ‰è½¦
        if best_iou >= overlap_threshold and best_confidence >= min_confidence_threshold:
            result[space.id] = True
            confidence_map[space.id] = best_confidence
            detection_regions[space.id] = (x, y, w, h)
            
            # æå–è½¦è¾†ç‰¹å¾
            if extract_features and best_car_box:
                try:
                    # ä»åŸå§‹å›¾åƒä¸­è£å‰ªè½¦è¾†åŒºåŸŸ
                    car_x1 = max(0, min(best_car_box["x1"], img_width))
                    car_y1 = max(0, min(best_car_box["y1"], img_height))
                    car_x2 = max(0, min(best_car_box["x2"], img_width))
                    car_y2 = max(0, min(best_car_box["y2"], img_height))
                    
                    if car_x2 > car_x1 and car_y2 > car_y1:
                        vehicle_roi = img[car_y1:car_y2, car_x1:car_x2]
                        if vehicle_roi.size > 0:
                            features = extract_vehicle_features(vehicle_roi)
                            features_map[space.id] = features
                except Exception as e:
                    print(f"[ParkingChangeWorker] æå–è½¦è¾†ç‰¹å¾å¤±è´¥: {e}")
            
            print(f"[ParkingChangeWorker] è½¦ä½ {space.space_name}: æœ‰è½¦ (IoU={best_iou:.3f}, ç½®ä¿¡åº¦={best_confidence:.3f})")
        else:
            result[space.id] = False
            confidence_map[space.id] = 0.0
            detection_regions[space.id] = (x, y, w, h)
            if best_iou >= overlap_threshold and best_confidence < min_confidence_threshold:
                print(f"[ParkingChangeWorker] è½¦ä½ {space.space_name}: æ— è½¦ (IoU={best_iou:.3f} >= {overlap_threshold}, ä½†ç½®ä¿¡åº¦={best_confidence:.3f} < {min_confidence_threshold:.3f})")
            elif best_iou > 0:
                print(f"[ParkingChangeWorker] è½¦ä½ {space.space_name}: æ— è½¦ (IoU={best_iou:.3f} < {overlap_threshold}, æœ€é«˜ç½®ä¿¡åº¦={best_confidence:.3f})")
            else:
                print(f"[ParkingChangeWorker] è½¦ä½ {space.space_name}: æ— è½¦ (æœªæ‰¾åˆ°åŒ¹é…çš„è½¦è¾†æ£€æµ‹æ¡†)")
    
    return result, detection_regions, confidence_map, features_map


def _draw_detection_regions(
    image_path: Path,
    spaces: List[ParkingSpace],
    detection_regions: Dict[int, Tuple[int, int, int, int]],
    output_path: Path | None = None,
) -> Path:
    """åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶ç»¿è‰²çº¿æ ‡è®°å®é™…æ£€æµ‹çš„åŒºåŸŸã€‚
    
    å‚æ•°:
        image_path: åŸå§‹å›¾ç‰‡è·¯å¾„
        spaces: è½¦ä½åˆ—è¡¨
        detection_regions: æ£€æµ‹åŒºåŸŸå­—å…¸ {space_id: (x, y, w, h)}
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨ç”Ÿæˆ
    
    è¿”å›:
        è¾“å‡ºå›¾ç‰‡è·¯å¾„
    """
    try:
        # è¯»å–å›¾ç‰‡
        img = cv2.imread(str(image_path))
        if img is None:
            print(f"[ParkingChangeWorker] è­¦å‘Š: æ— æ³•è¯»å–å›¾ç‰‡ç”¨äºç»˜åˆ¶æ£€æµ‹åŒºåŸŸ: {image_path}")
            return image_path
        
        # åˆ›å»º space_id åˆ° space çš„æ˜ å°„
        space_map = {space.id: space for space in spaces}
        
        # ç»˜åˆ¶æ¯ä¸ªæ£€æµ‹åŒºåŸŸï¼ˆç»¿è‰²æ¡†ï¼‰
        for space_id, region in detection_regions.items():
            x, y, w, h = region
            x1, y1 = x, y
            x2, y2 = x + w, y + h
            
            # ç»˜åˆ¶ç»¿è‰²çŸ©å½¢æ¡†ï¼ˆBGRæ ¼å¼ï¼Œç»¿è‰²æ˜¯ (0, 255, 0)ï¼‰
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # æ·»åŠ è½¦ä½åç§°æ ‡ç­¾
            space = space_map.get(space_id)
            if space and space.space_name:
                label = space.space_name
                # è®¡ç®—æ–‡å­—ä½ç½®ï¼ˆåœ¨æ¡†çš„ä¸Šæ–¹ï¼‰
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.6
                thickness = 2
                (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)
                
                # ç¡®ä¿æ–‡å­—ä¸è¶…å‡ºå›¾ç‰‡è¾¹ç•Œ
                text_x = max(0, min(x1, img.shape[1] - text_width))
                text_y = max(text_height + baseline, y1 - 5)
                
                # ç»˜åˆ¶æ–‡å­—èƒŒæ™¯ï¼ˆåŠé€æ˜é»‘è‰²ï¼‰
                cv2.rectangle(img, 
                            (text_x, text_y - text_height - baseline),
                            (text_x + text_width, text_y + baseline),
                            (0, 0, 0), -1)
                
                # ç»˜åˆ¶æ–‡å­—ï¼ˆç»¿è‰²ï¼‰
                cv2.putText(img, label, (text_x, text_y),
                          font, font_scale, (0, 255, 0), thickness)
        
        # ç¡®å®šè¾“å‡ºè·¯å¾„
        if output_path is None:
            # è‡ªåŠ¨ç”Ÿæˆï¼šåŸæ–‡ä»¶å_detected.jpg
            output_path = image_path.parent / f"{image_path.stem}_detected{image_path.suffix}"
        else:
            output_path = Path(output_path)
        
        # ä¿å­˜å›¾ç‰‡
        cv2.imwrite(str(output_path), img)
        print(f"[ParkingChangeWorker] âœ“ å·²ä¿å­˜æ£€æµ‹åŒºåŸŸæ ‡è®°å›¾: {output_path}")
        
        return output_path
        
    except Exception as e:
        print(f"[ParkingChangeWorker] ç»˜åˆ¶æ£€æµ‹åŒºåŸŸå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return image_path


def _get_channel_config_and_spaces(db, task: Task) -> Tuple[ChannelConfig | None, List[ParkingSpace]]:
    """æ ¹æ®ä»»åŠ¡çš„ IP + é€šé“æ‰¾åˆ°å¯¹åº”çš„ ChannelConfig åŠå…¶è½¦ä½åˆ—è¡¨ã€‚"""
    ip = (task.ip or "").strip()
    ch_code = (task.channel or "").strip().lower()
    if not ip or not ch_code:
        return None, []

    nvr = db.query(NvrConfig).filter(NvrConfig.nvr_ip == ip).first()
    if not nvr:
        return None, []

    channel_cfg = (
        db.query(ChannelConfig)
        .filter(
            ChannelConfig.nvr_config_id == nvr.id,
            ChannelConfig.channel_code == ch_code,
        )
        .first()
    )
    if not channel_cfg:
        return None, []

    spaces = (
        db.query(ParkingSpace)
        .filter(ParkingSpace.channel_config_id == channel_cfg.id)
        .all()
    )
    return channel_cfg, spaces


def _detect_weather_condition(img: np.ndarray, brightness: float, clarity: float) -> str:
    """æ£€æµ‹å¤©æ°”æ¡ä»¶ï¼ˆé›¨å¤©ã€é›¾å¤©ã€é˜´å¤©ã€æ™´å¤©ï¼‰ã€‚
    
    åŸºäºå›¾åƒç‰¹å¾åˆ†æï¼š
    - é›¨å¤©ï¼šè¾ƒæš—ã€æœ‰åå…‰åŒºåŸŸã€å¯¹æ¯”åº¦é™ä½ã€å¯èƒ½æœ‰æ°´ç ç‰¹å¾
    - é›¾å¤©ï¼šæ¨¡ç³Šã€å¯¹æ¯”åº¦ä½ã€æ•´ä½“åç°ç™½è‰²ã€èƒ½è§åº¦å·®
    - é˜´å¤©ï¼šå…‰ç…§å‡åŒ€ä½†è¾ƒæš—ã€å¯¹æ¯”åº¦é€‚ä¸­ã€æ— å¼ºçƒˆé˜´å½±
    - æ™´å¤©ï¼šå…‰ç…§å……è¶³ã€å¯¹æ¯”åº¦é«˜ã€å›¾åƒæ¸…æ™°ã€å¯èƒ½æœ‰å¼ºçƒˆé˜´å½±
    
    å‚æ•°:
        img: BGRå›¾åƒæ•°ç»„
        brightness: å¹³å‡äº®åº¦
        clarity: æ¸…æ™°åº¦ï¼ˆLaplacianæ–¹å·®ï¼‰
    
    è¿”å›:
        å¤©æ°”æ¡ä»¶å­—ç¬¦ä¸²ï¼š"rainy" | "foggy" | "cloudy" | "sunny"
    """
    try:
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img
        
        # è®¡ç®—å¯¹æ¯”åº¦ï¼ˆæ ‡å‡†å·®ï¼‰
        contrast = float(np.std(gray))
        
        # è®¡ç®—é¥±å’Œåº¦ï¼ˆHSV Sé€šé“çš„å¹³å‡å€¼ï¼‰
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) if len(img.shape) == 3 else None
        saturation = float(np.mean(hsv[:, :, 1])) if hsv is not None else 50.0
        
        # æ£€æµ‹é«˜å…‰åŒºåŸŸï¼ˆåå…‰ï¼Œå¯èƒ½æ˜¯é›¨å¤©ï¼‰
        high_brightness_ratio = float(np.sum(gray > 200) / gray.size)
        
        # æ£€æµ‹ä½å¯¹æ¯”åº¦åŒºåŸŸï¼ˆå¯èƒ½æ˜¯é›¾å¤©ï¼‰
        low_contrast_ratio = float(np.sum(np.abs(gray.astype(float) - brightness) < 20) / gray.size)
        
        # 1. é›¾å¤©æ£€æµ‹ï¼šæ¨¡ç³Š + ä½å¯¹æ¯”åº¦ + ä½é¥±å’Œåº¦
        if clarity < CLARITY_THRESHOLD * 0.7 and contrast < 30 and saturation < 40:
            return "foggy"
        
        # 2. é›¨å¤©æ£€æµ‹ï¼šè¾ƒæš— + æœ‰åå…‰åŒºåŸŸ + å¯¹æ¯”åº¦é™ä½
        if brightness < 100 and high_brightness_ratio > 0.05 and contrast < 40:
            return "rainy"
        
        # 3. é˜´å¤©æ£€æµ‹ï¼šå…‰ç…§å‡åŒ€ä½†è¾ƒæš— + å¯¹æ¯”åº¦é€‚ä¸­ + æ— å¼ºçƒˆé˜´å½±
        if brightness < 120 and 30 <= contrast <= 50 and saturation < 60:
            return "cloudy"
        
        # 4. æ™´å¤©ï¼šé»˜è®¤æƒ…å†µï¼ˆå…‰ç…§å……è¶³ã€å¯¹æ¯”åº¦é«˜ã€æ¸…æ™°ï¼‰
        return "sunny"
        
    except Exception as e:
        print(f"[ParkingChangeWorker] å¤©æ°”æ£€æµ‹å¤±è´¥: {e}")
        return "sunny"  # é»˜è®¤è¿”å›æ™´å¤©


def _determine_day_night(image_time: datetime | None, brightness: float) -> str:
    """åˆ¤æ–­æ˜¯ç™½å¤©è¿˜æ˜¯æ™šä¸Šã€‚
    
    ä¼˜å…ˆä½¿ç”¨æ—¶é—´åˆ¤æ–­ï¼Œå¦‚æœæ—¶é—´ä¸å¯ç”¨åˆ™ä½¿ç”¨å›¾åƒäº®åº¦åˆ¤æ–­ã€‚
    
    å‚æ•°:
        image_time: å›¾åƒæ—¶é—´ï¼ˆå¯é€‰ï¼‰
        brightness: å›¾åƒå¹³å‡äº®åº¦ (0-255)
    
    è¿”å›:
        "day" | "night"
    """
    if image_time:
        hour = image_time.hour
        # 6:00-18:00 è§†ä¸ºç™½å¤©ï¼Œå…¶ä»–æ—¶é—´è§†ä¸ºæ™šä¸Š
        if 6 <= hour < 18:
            return "day"
        else:
            return "night"
    else:
        # å¦‚æœæ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œä½¿ç”¨äº®åº¦åˆ¤æ–­
        # äº®åº¦ >= 100 è§†ä¸ºç™½å¤©ï¼Œ< 100 è§†ä¸ºæ™šä¸Š
        if brightness >= 100:
            return "day"
        else:
            return "night"


def _get_image_quality_description(image_quality: Dict[str, Any]) -> str:
    """ç”Ÿæˆå›¾åƒè´¨é‡çš„æ–‡å­—æè¿°ã€‚
    
    å‚æ•°:
        image_quality: å›¾åƒè´¨é‡åˆ†æç»“æœ
    
    è¿”å›:
        è´¨é‡æè¿°å­—ç¬¦ä¸²
    """
    brightness = image_quality.get("brightness", 128.0)
    clarity = image_quality.get("clarity", 100.0)
    interference_level = image_quality.get("interference_level", "normal")
    is_overexposed = image_quality.get("is_overexposed", False)
    is_underexposed = image_quality.get("is_underexposed", False)
    is_blurry = image_quality.get("is_blurry", False)
    weather = image_quality.get("weather", "sunny")
    
    quality_parts = []
    
    # äº®åº¦è¯„ä¼°
    if is_overexposed:
        quality_parts.append("è¿‡æ›")
    elif is_underexposed:
        quality_parts.append("æ¬ æ›")
    elif brightness < 80:
        quality_parts.append("è¾ƒæš—")
    elif brightness < 120:
        quality_parts.append("åæš—")
    elif brightness > 200:
        quality_parts.append("è¾ƒäº®")
    else:
        quality_parts.append("äº®åº¦æ­£å¸¸")
    
    # æ¸…æ™°åº¦è¯„ä¼°
    if is_blurry:
        quality_parts.append("æ¨¡ç³Š")
    elif clarity < CLARITY_THRESHOLD * 0.7:
        quality_parts.append("æ¸…æ™°åº¦è¾ƒä½")
    elif clarity < CLARITY_THRESHOLD:
        quality_parts.append("æ¸…æ™°åº¦ä¸€èˆ¬")
    else:
        quality_parts.append("æ¸…æ™°")
    
    # å¹²æ‰°ç­‰çº§
    interference_names = {"high": "é«˜å¹²æ‰°", "normal": "ä¸­ç­‰å¹²æ‰°", "low": "ä½å¹²æ‰°"}
    quality_parts.append(interference_names.get(interference_level, "æœªçŸ¥"))
    
    # å¤©æ°”
    weather_names = {"rainy": "é›¨å¤©", "foggy": "é›¾å¤©", "cloudy": "é˜´å¤©", "sunny": "æ™´å¤©"}
    quality_parts.append(weather_names.get(weather, "æœªçŸ¥"))
    
    return " | ".join(quality_parts)


def _analyze_image_quality(image_path: Path, image_time: datetime | None = None) -> Dict[str, Any]:
    """åˆ†æå›¾åƒè´¨é‡ï¼Œåˆ¤å®šå¹²æ‰°ç­‰çº§å’Œå¤©æ°”æ¡ä»¶ã€‚
    
    å‚æ•°:
        image_path: å›¾åƒè·¯å¾„
        image_time: å›¾åƒæ—¶é—´ï¼ˆå¯é€‰ï¼Œç”¨äºåˆ¤æ–­ç™½å¤©/æ™šä¸Šï¼‰
    
    è¿”å›:
        {
            "brightness": float,  # å¹³å‡äº®åº¦ (0-255)
            "clarity": float,  # æ¸…æ™°åº¦ (Laplacianæ–¹å·®)
            "interference_level": str,  # "high", "normal", "low"
            "is_overexposed": bool,  # æ˜¯å¦è¿‡æ›
            "is_underexposed": bool,  # æ˜¯å¦æ¬ æ›
            "is_blurry": bool,  # æ˜¯å¦æ¨¡ç³Š
            "weather": str,  # å¤©æ°”æ¡ä»¶ "rainy" | "foggy" | "cloudy" | "sunny"
            "day_night": str,  # "day" | "night"
            "quality_description": str,  # è´¨é‡æè¿°æ–‡å­—
        }
    """
    try:
        img = cv2.imread(str(image_path))
        if img is None:
            return {
                "brightness": 128.0,
                "clarity": 0.0,
                "interference_level": "high",
                "is_overexposed": False,
                "is_underexposed": False,
                "is_blurry": True,
                "weather": "sunny",
            }
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—å¹³å‡äº®åº¦
        brightness = float(np.mean(gray))
        
        # è®¡ç®—æ¸…æ™°åº¦ï¼ˆLaplacianæ–¹å·®ï¼‰
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        clarity = float(laplacian_var)
        
        # åˆ¤å®šå¹²æ‰°ç­‰çº§
        is_overexposed = brightness > BRIGHTNESS_HIGH_THRESHOLD
        is_underexposed = brightness < BRIGHTNESS_LOW_THRESHOLD
        is_blurry = clarity < CLARITY_THRESHOLD
        
        if is_overexposed or is_underexposed or is_blurry:
            interference_level = "high"
        elif abs(brightness - 128) > 30 or clarity < CLARITY_THRESHOLD * 1.5:
            interference_level = "normal"
        else:
            interference_level = "low"
        
        # æ£€æµ‹å¤©æ°”æ¡ä»¶
        weather = _detect_weather_condition(img, brightness, clarity)
        
        # åˆ¤æ–­ç™½å¤©/æ™šä¸Š
        day_night = _determine_day_night(image_time, brightness)
        
        # ç”Ÿæˆè´¨é‡æè¿°
        quality_result = {
            "brightness": brightness,
            "clarity": clarity,
            "interference_level": interference_level,
            "is_overexposed": is_overexposed,
            "is_underexposed": is_underexposed,
            "is_blurry": is_blurry,
            "weather": weather,
            "day_night": day_night,
        }
        quality_description = _get_image_quality_description(quality_result)
        quality_result["quality_description"] = quality_description
        
        return quality_result
    except Exception as e:
        print(f"[ParkingChangeWorker] å›¾åƒè´¨é‡åˆ†æå¤±è´¥: {e}")
        return {
            "brightness": 128.0,
            "clarity": 0.0,
            "interference_level": "high",
            "is_overexposed": False,
            "is_underexposed": False,
            "is_blurry": True,
            "weather": "sunny",
            "day_night": "day",
            "quality_description": "åˆ†æå¤±è´¥",
        }


def _calculate_dynamic_similarity_threshold(
    base_threshold: float,
    current_time: datetime,
    prev_time: datetime | None,
    image_quality_curr: Dict[str, Any],
    image_quality_prev: Dict[str, Any] | None = None,
    time_diff_seconds: float | None = None,
    is_short_interval: bool = False,
    is_cross_day: bool = False,
) -> Tuple[float, str]:
    """æ ¹æ®æ—¶é—´æ®µã€å›¾åƒè´¨é‡å’Œæ—¶é—´é—´éš”åŠ¨æ€è®¡ç®—ç›¸ä¼¼åº¦é˜ˆå€¼ã€‚
    
    è€ƒè™‘å› ç´ ï¼š
    1. æ—¶é—´æ®µï¼ˆå‡Œæ™¨ã€ç™½å¤©ã€å‚æ™šã€å¤œé—´ï¼‰- ä¸åŒæ—¶é—´æ®µå…‰ç…§æ¡ä»¶ä¸åŒ
    2. å›¾åƒè´¨é‡ï¼ˆäº®åº¦ã€æ¸…æ™°åº¦ï¼‰- æš—å…‰/æ¨¡ç³Šç¯å¢ƒä¸‹ç‰¹å¾æå–ä¸ç¨³å®š
    3. æ—¶é—´é—´éš”ï¼ˆçŸ­é—´éš”ã€é•¿é—´éš”ï¼‰- çŸ­é—´éš”æ—¶è½¦è¾†å˜åŒ–å¯èƒ½æ€§ä½
    4. è·¨å¤©æƒ…å†µ - è·¨å¤©æ—¶é˜ˆå€¼é™ä½
    
    å‚æ•°:
        base_threshold: åŸºç¡€é˜ˆå€¼
        current_time: å½“å‰æˆªå›¾æ—¶é—´
        prev_time: ä¸Šä¸€å¼ æˆªå›¾æ—¶é—´
        image_quality_curr: å½“å‰å›¾åƒè´¨é‡åˆ†æç»“æœ
        image_quality_prev: ä¸Šä¸€å¼ å›¾åƒè´¨é‡åˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
        time_diff_seconds: æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
        is_short_interval: æ˜¯å¦ä¸ºçŸ­æ—¶é—´é—´éš”
        is_cross_day: æ˜¯å¦è·¨å¤©
    
    è¿”å›:
        (è°ƒæ•´åçš„é˜ˆå€¼, é˜ˆå€¼æè¿°å­—ç¬¦ä¸²)
    """
    threshold = base_threshold
    adjustments = []
    
    # 1. çŸ­æ—¶é—´é—´éš”ï¼šæœ€ä¼˜å…ˆï¼Œä½¿ç”¨æœ€å®½æ¾çš„é˜ˆå€¼
    if is_short_interval and time_diff_seconds is not None:
        threshold = VEHICLE_SIMILARITY_THRESHOLD_SHORT_INTERVAL
        adjustments.append(f"çŸ­é—´éš”({time_diff_seconds:.0f}ç§’)")
        return threshold, "çŸ­é—´éš”"
    
    # 2. è·¨å¤©ï¼šä½¿ç”¨è·¨å¤©é˜ˆå€¼
    if is_cross_day:
        threshold = VEHICLE_SIMILARITY_THRESHOLD_CROSS_DAY
        adjustments.append("è·¨å¤©")
        return threshold, "è·¨å¤©"
    
    # 3. æ—¶é—´æ®µè°ƒæ•´ï¼ˆåŸºäºå½“å‰æ—¶é—´ï¼‰
    current_hour = current_time.hour
    time_period_factor = 1.0
    time_period_name = ""
    
    if TIME_PERIOD_EARLY_MORNING[0] <= current_hour < TIME_PERIOD_EARLY_MORNING[1]:
        # å‡Œæ™¨ 0-6ç‚¹
        time_period_factor = TIME_PERIOD_THRESHOLD_FACTOR_EARLY_MORNING
        time_period_name = "å‡Œæ™¨"
    elif TIME_PERIOD_DAYTIME[0] <= current_hour < TIME_PERIOD_DAYTIME[1]:
        # ç™½å¤© 6-18ç‚¹
        time_period_factor = TIME_PERIOD_THRESHOLD_FACTOR_DAYTIME
        time_period_name = "ç™½å¤©"
    elif TIME_PERIOD_EVENING[0] <= current_hour < TIME_PERIOD_EVENING[1]:
        # å‚æ™š 18-20ç‚¹
        time_period_factor = TIME_PERIOD_THRESHOLD_FACTOR_EVENING
        time_period_name = "å‚æ™š"
    else:
        # å¤œé—´ 20-24ç‚¹
        time_period_factor = TIME_PERIOD_THRESHOLD_FACTOR_NIGHT
        time_period_name = "å¤œé—´"
    
    threshold *= time_period_factor
    if time_period_factor < 1.0:
        adjustments.append(f"{time_period_name}(ç³»æ•°{time_period_factor:.2f})")
    
    # 4. å›¾åƒè´¨é‡è°ƒæ•´ï¼ˆäº®åº¦ï¼‰
    brightness_curr = image_quality_curr.get("brightness", 128.0)
    brightness_factor = 1.0
    
    if brightness_curr < 50:
        # ææš—ç¯å¢ƒ
        brightness_factor = BRIGHTNESS_THRESHOLD_FACTOR_VERY_DARK
        adjustments.append(f"ææš—(äº®åº¦{brightness_curr:.1f})")
    elif brightness_curr < 80:
        # æš—å…‰ç¯å¢ƒ
        brightness_factor = BRIGHTNESS_THRESHOLD_FACTOR_DARK
        adjustments.append(f"æš—å…‰(äº®åº¦{brightness_curr:.1f})")
    
    threshold *= brightness_factor
    
    # 5. å›¾åƒè´¨é‡è°ƒæ•´ï¼ˆæ¸…æ™°åº¦ï¼‰
    clarity_curr = image_quality_curr.get("clarity", 100.0)
    if clarity_curr < CLARITY_THRESHOLD:
        # ä½æ¸…æ™°åº¦
        threshold *= CLARITY_THRESHOLD_FACTOR_LOW
        adjustments.append(f"æ¨¡ç³Š(æ¸…æ™°åº¦{clarity_curr:.1f})")
    
    # 6. å¤©æ°”æ¡ä»¶è°ƒæ•´
    weather_curr = image_quality_curr.get("weather", "sunny")
    weather_factor = 1.0
    
    if weather_curr == "rainy":
        weather_factor = WEATHER_THRESHOLD_FACTOR_RAINY
        adjustments.append("é›¨å¤©")
    elif weather_curr == "foggy":
        weather_factor = WEATHER_THRESHOLD_FACTOR_FOGGY
        adjustments.append("é›¾å¤©")
    elif weather_curr == "cloudy":
        weather_factor = WEATHER_THRESHOLD_FACTOR_CLOUDY
        adjustments.append("é˜´å¤©")
    # sunny: weather_factor = 1.0 (æ ‡å‡†)
    
    threshold *= weather_factor
    
    # 7. å¦‚æœä¸¤å¼ å›¾éƒ½åœ¨æš—å…‰ç¯å¢ƒï¼Œè¿›ä¸€æ­¥æ”¾å®½
    if prev_time and image_quality_prev:
        brightness_prev = image_quality_prev.get("brightness", 128.0)
        if brightness_curr < 80 and brightness_prev < 80:
            # ä¸¤å¼ å›¾éƒ½åœ¨æš—å…‰ç¯å¢ƒï¼Œç‰¹å¾æå–éƒ½ä¸ç¨³å®šï¼Œè¿›ä¸€æ­¥æ”¾å®½
            threshold *= 0.95
            adjustments.append("åŒæš—å…‰ç¯å¢ƒ")
        
        # å¦‚æœä¸¤å¼ å›¾å¤©æ°”æ¡ä»¶éƒ½ä¸å¥½ï¼ˆé›¨å¤©æˆ–é›¾å¤©ï¼‰ï¼Œè¿›ä¸€æ­¥æ”¾å®½
        weather_prev = image_quality_prev.get("weather", "sunny")
        if weather_curr in ("rainy", "foggy") and weather_prev in ("rainy", "foggy"):
            threshold *= 0.95
            adjustments.append("åŒæ¶åŠ£å¤©æ°”")
    
    # ç¡®ä¿é˜ˆå€¼ä¸ä½äºæœ€å°å€¼
    min_threshold = 0.50  # æœ€ä½é˜ˆå€¼50%
    threshold = max(min_threshold, threshold)
    
    # ç”Ÿæˆæè¿°å­—ç¬¦ä¸²
    if adjustments:
        # å¦‚æœæœ‰è°ƒæ•´é¡¹ï¼Œç»„åˆæ—¶é—´æ®µå’Œè°ƒæ•´é¡¹
        if time_period_name:
            threshold_desc = f"{time_period_name} + " + " + ".join(adjustments)
        else:
            threshold_desc = " + ".join(adjustments)
    else:
        # å¦‚æœæ²¡æœ‰è°ƒæ•´é¡¹ï¼Œåªæ˜¾ç¤ºæ—¶é—´æ®µ
        threshold_desc = time_period_name or "æ ‡å‡†"
    
    return threshold, threshold_desc


def _compare_vehicle_features(
    features_curr: Dict[str, Any],
    features_prev: Dict[str, Any],
    is_cross_day: bool = False,
) -> float:
    """æ¯”å¯¹ä¸¤è¾†è½¦çš„ç‰¹å¾ï¼Œè¿”å›ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆ0.0-1.0ï¼‰ã€‚
    
    ä½¿ç”¨ Hellinger è·ç¦»è®¡ç®—ç›´æ–¹å›¾ç›¸ä¼¼åº¦ï¼ŒåŠ æƒèåˆé¢œè‰²ã€å½¢çŠ¶ã€ç»“æ„ç‰¹å¾ã€‚
    
    å‚æ•°:
        features_curr: å½“å‰è½¦è¾†ç‰¹å¾
        features_prev: å†å²è½¦è¾†ç‰¹å¾
        is_cross_day: æ˜¯å¦è·¨å¤©ï¼ˆè·¨å¤©æ—¶é˜ˆå€¼é™ä½ï¼‰
    
    è¿”å›:
        ç›¸ä¼¼åº¦å¾—åˆ† (0.0-1.0)ï¼Œ1.0 è¡¨ç¤ºå®Œå…¨ç›¸åŒ
    """
    try:
        # æå–ç›´æ–¹å›¾
        hist_h_curr = np.array(features_curr.get("color_hist_h", [0.0] * 32))
        hist_s_curr = np.array(features_curr.get("color_hist_s", [0.0] * 32))
        hist_h_prev = np.array(features_prev.get("color_hist_h", [0.0] * 32))
        hist_s_prev = np.array(features_prev.get("color_hist_s", [0.0] * 32))
        
        # è®¡ç®— Hellinger è·ç¦»ï¼ˆç›´æ–¹å›¾ç›¸ä¼¼åº¦ï¼‰
        # Hellinger è·ç¦» = sqrt(sum((sqrt(p_i) - sqrt(q_i))^2)) / sqrt(2)
        # ç›¸ä¼¼åº¦ = 1 - Hellingerè·ç¦»
        def hellinger_distance(p, q):
            p_sqrt = np.sqrt(p + 1e-10)
            q_sqrt = np.sqrt(q + 1e-10)
            return np.sqrt(np.sum((p_sqrt - q_sqrt) ** 2)) / np.sqrt(2)
        
        dist_h = hellinger_distance(hist_h_curr, hist_h_prev)
        dist_s = hellinger_distance(hist_s_curr, hist_s_prev)
        similarity_color = 1.0 - (dist_h + dist_s) / 2.0
        
        # å®½é«˜æ¯”ç›¸ä¼¼åº¦
        aspect_curr = features_curr.get("aspect_ratio", 1.8)
        aspect_prev = features_prev.get("aspect_ratio", 1.8)
        aspect_diff = abs(aspect_curr - aspect_prev) / max(aspect_curr, aspect_prev, 1e-6)
        similarity_aspect = 1.0 - min(aspect_diff, 1.0)
        
        # é›¨åˆ®ç‰¹å¾ç›¸ä¼¼åº¦ï¼ˆå¸ƒå°”å€¼ï¼‰
        wiper_curr = features_curr.get("has_rear_wiper", False)
        wiper_prev = features_prev.get("has_rear_wiper", False)
        similarity_wiper = 1.0 if wiper_curr == wiper_prev else 0.5
        
        # åŠ æƒèåˆï¼ˆé¢œè‰²æƒé‡æœ€é«˜ï¼‰
        # åœ¨å¤œé—´ç¯å¢ƒä¸‹ï¼Œæé«˜é¢œè‰²ç›¸ä¼¼åº¦çš„æƒé‡ï¼ˆå› ä¸ºå…‰ç…§å˜åŒ–ä¸»è¦å½±å“é¢œè‰²ï¼‰
        # åŒæ—¶é™ä½å®½é«˜æ¯”å’Œé›¨åˆ®ç‰¹å¾çš„æƒé‡ï¼ˆå› ä¸ºè¿™äº›ç‰¹å¾åœ¨å¤œé—´æ›´ä¸ç¨³å®šï¼‰
        # é€šè¿‡ç›´æ–¹å›¾çš„å¹³å‡å€¼æ¥åˆ¤æ–­æ˜¯å¦ä¸ºå¤œé—´ç¯å¢ƒ
        hist_h_mean_curr = np.mean(hist_h_curr)
        hist_s_mean_curr = np.mean(hist_s_curr)
        hist_h_mean_prev = np.mean(hist_h_prev)
        hist_s_mean_prev = np.mean(hist_s_prev)
        # å¦‚æœç›´æ–¹å›¾æ•´ä½“è¾ƒæš—ï¼ˆHé€šé“å’ŒSé€šé“çš„å€¼éƒ½è¾ƒä½ï¼‰ï¼Œå¯èƒ½æ˜¯å¤œé—´ç¯å¢ƒ
        is_likely_dark = (hist_h_mean_curr < 0.1 and hist_s_mean_curr < 0.1) or \
                        (hist_h_mean_prev < 0.1 and hist_s_mean_prev < 0.1)
        
        if is_likely_dark:
            # å¤œé—´ç¯å¢ƒä¸‹ï¼Œæé«˜é¢œè‰²ç›¸ä¼¼åº¦æƒé‡ï¼Œé™ä½å…¶ä»–ç‰¹å¾æƒé‡
            # å› ä¸ºå¤œé—´å…‰ç…§å˜åŒ–ä¸»è¦å½±å“é¢œè‰²ï¼Œè€Œå½¢çŠ¶ç‰¹å¾ç›¸å¯¹ç¨³å®š
            similarity = (
                similarity_color * 0.70 +
                similarity_aspect * 0.20 +
                similarity_wiper * 0.10
            )
        else:
            # æ ‡å‡†æƒé‡
            similarity = (
                similarity_color * 0.60 +
                similarity_aspect * 0.30 +
                similarity_wiper * 0.10
            )
        
        return float(max(0.0, min(1.0, similarity)))
    except Exception as e:
        print(f"[ParkingChangeWorker] ç‰¹å¾æ¯”å¯¹å¤±è´¥: {e}")
        return 0.0


def _verify_and_revoke_false_leave(
    db,
    channel_config_id: int,
    space_id: int,
    space_name: str,
    current_screenshot_id: int,
    current_screenshot_time: datetime,
    current_has_car: bool,
) -> bool:
    """éªŒè¯å¹¶æ’¤é”€è¯¯åˆ¤çš„"ç¦»å¼€"äº‹ä»¶ã€‚
    
    æ£€æŸ¥ä¸Šä¸€å¼ æˆªå›¾ï¼ˆçº¦10åˆ†é’Ÿå‰ï¼‰æ˜¯å¦æœ‰è¯¥è½¦ä½çš„"leave"äº‹ä»¶ã€‚
    å¦‚æœå½“å‰æˆªå›¾æ˜¾ç¤ºè½¦ä½æœ‰è½¦ï¼Œåˆ™æ’¤é”€ä¹‹å‰çš„"leave"åˆ¤å®šã€‚
    
    å‚æ•°:
        db: æ•°æ®åº“ä¼šè¯
        channel_config_id: é€šé“é…ç½®ID
        space_id: è½¦ä½ID
        space_name: è½¦ä½åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        current_screenshot_id: å½“å‰æˆªå›¾ID
        current_screenshot_time: å½“å‰æˆªå›¾æ—¶é—´
        current_has_car: å½“å‰æˆªå›¾è¯¥è½¦ä½æ˜¯å¦æœ‰è½¦
    
    è¿”å›:
        True å¦‚æœæ’¤é”€äº†è¯¯åˆ¤çš„leaveäº‹ä»¶ï¼ŒFalse å¦åˆ™
    """
    if not current_has_car:
        # å½“å‰æ— è½¦ï¼Œä¸æ’¤é”€
        return False
    
    try:
        # æŸ¥æ‰¾ä¸Šä¸€å¼ æˆªå›¾ï¼ˆçº¦10åˆ†é’Ÿå‰ï¼‰ä¸­è¯¥è½¦ä½çš„"leave"äº‹ä»¶
        # æ—¶é—´èŒƒå›´ï¼š5-15åˆ†é’Ÿå‰ï¼ˆå…è®¸ä¸€å®šå®¹å·®ï¼‰
        time_min = current_screenshot_time - timedelta(seconds=900)  # 15åˆ†é’Ÿå‰
        time_max = current_screenshot_time - timedelta(seconds=300)   # 5åˆ†é’Ÿå‰
        
        prev_leave_change = (
            db.query(ParkingChange)
            .join(Screenshot, ParkingChange.screenshot_id == Screenshot.id)
            .filter(
                ParkingChange.channel_config_id == channel_config_id,
                ParkingChange.space_id == space_id,
                ParkingChange.change_type == "leave",  # åªæŸ¥æ‰¾leaveäº‹ä»¶
                Screenshot.id < current_screenshot_id,  # å¿…é¡»æ˜¯ä¹‹å‰çš„æˆªå›¾
                Screenshot.created_at >= time_min,
                Screenshot.created_at <= time_max,
            )
            .order_by(desc(Screenshot.created_at))  # æ‰¾åˆ°æœ€è¿‘çš„ä¸€ä¸ª
            .first()
        )
        
        if not prev_leave_change:
            return False
        
        # æ‰¾åˆ°äº†å¾…ç¡®è®¤çš„leaveäº‹ä»¶ï¼Œå½“å‰æˆªå›¾æ˜¾ç¤ºæœ‰è½¦ï¼Œè¯´æ˜æ˜¯è¯¯åˆ¤
        print(f"[ParkingChangeWorker] ğŸ” å‘ç°å¾…ç¡®è®¤çš„leaveäº‹ä»¶:")
        print(f"   è½¦ä½: {space_name}")
        print(f"   ä¸Šä¸€å¼ æˆªå›¾ID: {prev_leave_change.screenshot_id}")
        print(f"   å½“å‰æˆªå›¾ID: {current_screenshot_id}")
        print(f"   å½“å‰æ£€æµ‹: æœ‰è½¦")
        print(f"   âš ï¸  ä¸Šä¸€å¼ åˆ¤å®šä¸º'ç¦»å¼€'ï¼Œä½†å½“å‰æœ‰è½¦ -> åˆ¤å®šä¸ºè¯¯åˆ¤ï¼ˆå¯èƒ½æ˜¯è·¯è¿‡è½¦è¾†é®æŒ¡ï¼‰")
        
        # æ›´æ–°ä¹‹å‰çš„leaveè®°å½•ä¸º"æ— å˜åŒ–"
        prev_leave_change.change_type = None
        # æ›´æ–°curr_occupiedä¸ºTrueï¼ˆå› ä¸ºå½“å‰æœ‰è½¦ï¼Œè¯´æ˜ä¹‹å‰çš„çŠ¶æ€åº”è¯¥æ˜¯æœ‰è½¦ï¼‰
        prev_leave_change.curr_occupied = True
        
        # æ›´æ–°å¿«ç…§è®°å½•ï¼šå‡å°‘change_count
        prev_snapshot = (
            db.query(ParkingChangeSnapshot)
            .filter(ParkingChangeSnapshot.screenshot_id == prev_leave_change.screenshot_id)
            .first()
        )
        if prev_snapshot and prev_snapshot.change_count > 0:
            old_count = prev_snapshot.change_count
            prev_snapshot.change_count -= 1
            print(f"   âœ“ å·²æ›´æ–°å¿«ç…§è®°å½• (screenshot_id={prev_leave_change.screenshot_id})ï¼Œchange_count: {old_count} -> {prev_snapshot.change_count}")
            
            # å¦‚æœchange_countå˜ä¸º0ï¼Œå¯ä»¥è€ƒè™‘åˆ é™¤å¿«ç…§è®°å½•ï¼ˆä½†ä¿ç•™å˜åŒ–è®°å½•ï¼‰
            if prev_snapshot.change_count == 0:
                print(f"   âš ï¸  å¿«ç…§è®°å½•çš„change_countå·²ä¸º0ï¼Œä½†ä¿ç•™å¿«ç…§è®°å½•ä»¥ä¾¿è¿½æº¯")
        
        print(f"   âœ“ å·²æ’¤é”€è¯¯åˆ¤çš„leaveäº‹ä»¶ï¼Œæ›´æ–°ä¸º'æ— å˜åŒ–'")
        return True
        
    except Exception as e:
        print(f"[ParkingChangeWorker] éªŒè¯leaveäº‹ä»¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def _get_prev_occupied_for_channel(
    db,
    channel_config_id: int,
    space_id: int,
    current_screenshot_id: int,
    current_screenshot_time: datetime | None = None,
    current_task_id: int = None,  # ä¸ºå…¼å®¹æ—§è°ƒç”¨ä¿ç•™å‚æ•°ï¼Œä½†ä¸å†ç”¨äºè¿‡æ»¤
    max_time_gap_seconds: int = 3600,  # æœ€å¤§æ—¶é—´é—´éš”ï¼ˆé»˜è®¤1å°æ—¶ï¼‰
) -> Tuple[bool | None, int | None, Dict[str, Any] | None]:
    """è·å–åŒä¸€é€šé“ä¸‹è¯¥è½¦ä½åœ¨ä¸Šä¸€å¼ æˆªå›¾ä¸­çš„å ç”¨çŠ¶æ€ï¼ˆæŒ‰æˆªå›¾æ—¶é—´é¡ºåºï¼Œå…¨å±€è¿ç»­æ¯”è¾ƒï¼‰ã€‚

    é€»è¾‘è¯´æ˜ï¼š
    - ä¸å†å±€é™äºâ€œåŒä¸€ task_idâ€ï¼Œè€Œæ˜¯åŸºäº channel_config_id + screenshot_id
      åœ¨æ•´ä¸ªæ—¶é—´çº¿ä¸Šè¿ç»­æ¯”è¾ƒï¼šå›¾1å¯¹æ¯”å›¾2ï¼Œå›¾2å¯¹æ¯”å›¾3ï¼Œå›¾3å¯¹æ¯”å›¾4...
    - è¿™æ ·å¯ä»¥è·¨ Task è¿ç»­è¿½è¸ªåŒä¸€é€šé“çš„è½¦ä½å˜åŒ–ï¼Œæ›´ç¬¦åˆâ€œåŒä¸€é€šé“â€çš„ä¸šåŠ¡è¯­ä¹‰ã€‚
    """
    # è·å–å½“å‰æˆªå›¾çš„æ—¶é—´ï¼ˆå¿…é¡»ï¼‰
    if current_screenshot_time is None:
        current_screenshot = db.query(Screenshot).filter(Screenshot.id == current_screenshot_id).first()
        if current_screenshot and current_screenshot.created_at:
            current_screenshot_time = current_screenshot.created_at
        else:
            # å¦‚æœæ²¡æœ‰æ—¶é—´ä¿¡æ¯ï¼Œæ— æ³•è¿›è¡Œæ—¶é—´é¡ºåºå¯¹æ¯”ï¼Œè¿”å› None
            return None, None, None
    
    # åœ¨ ParkingChange è¡¨ä¸­æŸ¥æ‰¾åŒä¸€é€šé“ã€åŒä¸€è½¦ä½ã€å½“å‰æˆªå›¾æ—¶é—´ä¹‹å‰æœ€è¿‘çš„ä¸€æ¡è®°å½•
    # å¿…é¡»æŒ‰æ—¶é—´æ’åºï¼Œä¸èƒ½æŒ‰ screenshot_id æ’åº
    prev_change = (
        db.query(ParkingChange)
        .join(Screenshot, ParkingChange.screenshot_id == Screenshot.id)
        .filter(
            ParkingChange.channel_config_id == channel_config_id,
            ParkingChange.space_id == space_id,
            Screenshot.created_at < current_screenshot_time,  # æŒ‰æ—¶é—´è¿‡æ»¤ï¼Œä¸æ˜¯æŒ‰ID
        )
        .order_by(desc(Screenshot.created_at))  # æŒ‰æ—¶é—´é™åºï¼Œæ‰¾åˆ°æ—¶é—´ä¸Šæœ€è¿‘çš„ä¸€å¼ 
        .first()
    )

    if not prev_change:
        # æ²¡æœ‰ä»»ä½•å†å²è®°å½•ï¼Œè§†ä¸ºç¬¬ä¸€å¼ ï¼ˆä¸Šä¸€å¼ çŠ¶æ€æœªçŸ¥ï¼‰
        return None, None, None
    
    # æ£€æŸ¥æ—¶é—´é—´éš”ï¼ˆå¿…é¡»æ£€æŸ¥ï¼Œç¡®ä¿ä¸è·³è¿‡ä¸­é—´çš„æˆªå›¾ï¼‰
    if prev_change.detected_at:
        time_gap = (current_screenshot_time - prev_change.detected_at).total_seconds()
        if time_gap > max_time_gap_seconds:
            # æ—¶é—´é—´éš”è¿‡å¤§ï¼ˆä¾‹å¦‚è¶…è¿‡15åˆ†é’Ÿï¼‰ï¼Œè¯´æ˜è·³è¿‡äº†ä¸­é—´çš„æˆªå›¾ï¼Œè¿”å› None
            # è¿™æ ·å¯ä»¥é¿å… 10:00 ç›´æ¥å¯¹æ¯” 10:30 çš„æƒ…å†µ
            print(f"[ParkingChangeWorker] è­¦å‘Š: æ—¶é—´é—´éš”è¿‡å¤§ ({time_gap:.0f}ç§’ > {max_time_gap_seconds}ç§’)ï¼Œè·³è¿‡å¯¹æ¯”ã€‚å½“å‰: {current_screenshot_time}, ä¸Šä¸€å¼ : {prev_change.detected_at}")
            return None, None, None
    
    # è·å–ä¸Šä¸€å¸§çš„è½¦è¾†ç‰¹å¾
    prev_features = prev_change.vehicle_features if prev_change.vehicle_features else None
    
    # ç›´æ¥ä½¿ç”¨ä¸Šä¸€æ¡è®°å½•ä¸­çš„ curr_occupied ä½œä¸ºä¸Šä¸€å¼ å›¾çš„çŠ¶æ€
    return prev_change.curr_occupied, prev_change.screenshot_id, prev_features


def _calculate_position_offset(
    region_curr: Tuple[int, int, int, int] | None,
    region_prev: Tuple[int, int, int, int] | None,
    space_width: int,
) -> float | None:
    """è®¡ç®—ä¸¤ä¸ªæ£€æµ‹åŒºåŸŸä¹‹é—´çš„ä½ç½®åç§»ï¼ˆç›¸å¯¹äºè½¦ä½å®½åº¦çš„æ¯”ä¾‹ï¼‰ã€‚
    
    å‚æ•°:
        region_curr: å½“å‰æ£€æµ‹åŒºåŸŸ (x, y, w, h)
        region_prev: ä¸Šä¸€å¸§æ£€æµ‹åŒºåŸŸ (x, y, w, h)
        space_width: è½¦ä½å®½åº¦ï¼ˆåƒç´ ï¼‰
    
    è¿”å›:
        ä½ç½®åç§»æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰ï¼ŒNone è¡¨ç¤ºæ— æ³•è®¡ç®—
    """
    if not region_curr or not region_prev or space_width <= 0:
        return None
    
    x_curr, y_curr, w_curr, h_curr = region_curr
    x_prev, y_prev, w_prev, h_prev = region_prev
    
    # è®¡ç®—ä¸­å¿ƒç‚¹
    center_x_curr = x_curr + w_curr / 2
    center_y_curr = y_curr + h_curr / 2
    center_x_prev = x_prev + w_prev / 2
    center_y_prev = y_prev + h_prev / 2
    
    # è®¡ç®—æ¬§æ°è·ç¦»
    distance = ((center_x_curr - center_x_prev) ** 2 + (center_y_curr - center_y_prev) ** 2) ** 0.5
    
    # è½¬æ¢ä¸ºç›¸å¯¹äºè½¦ä½å®½åº¦çš„æ¯”ä¾‹
    offset_ratio = distance / space_width if space_width > 0 else None
    
    return offset_ratio


def _check_state_lock(
    db,
    channel_config_id: int,
    space_id: int,
    current_screenshot_time: datetime,
    max_time_gap_seconds: int = 900,  # 15åˆ†é’Ÿ
) -> Tuple[bool, int]:
    """æ£€æŸ¥è½¦ä½çŠ¶æ€æ˜¯å¦å·²é”å®šï¼Œä»¥åŠè¿ç»­æ— è½¦å¸§æ•°ã€‚
    
    çŠ¶æ€é”é€»è¾‘ï¼š
    - å¦‚æœè¿ç»­ STATE_LOCK_FRAMES å¸§çŠ¶æ€ä¸å˜ï¼Œåˆ™é”å®šçŠ¶æ€
    - å¦‚æœçŠ¶æ€å·²é”å®šï¼Œå¿…é¡»è¿ç»­ STATE_UNLOCK_FRAMES å¸§æ£€æµ‹åˆ°æ— è½¦æ‰å…è®¸ç¦»å¼€
    
    å‚æ•°:
        db: æ•°æ®åº“ä¼šè¯
        channel_config_id: é€šé“é…ç½®ID
        space_id: è½¦ä½ID
        current_screenshot_time: å½“å‰æˆªå›¾æ—¶é—´
        max_time_gap_seconds: æœ€å¤§æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
    
    è¿”å›:
        (is_locked, consecutive_empty_frames)
        - is_locked: çŠ¶æ€æ˜¯å¦å·²é”å®š
        - consecutive_empty_frames: è¿ç»­æ— è½¦å¸§æ•°
    """
    if not STATE_LOCK_ENABLED:
        return False, 0
    
    try:
        # æŸ¥è¯¢æœ€è¿‘ STATE_LOCK_FRAMES + STATE_UNLOCK_FRAMES å¸§çš„è®°å½•
        recent_changes = (
            db.query(ParkingChange)
            .join(Screenshot, ParkingChange.screenshot_id == Screenshot.id)
            .filter(
                ParkingChange.channel_config_id == channel_config_id,
                ParkingChange.space_id == space_id,
                Screenshot.created_at < current_screenshot_time,
            )
            .order_by(desc(Screenshot.created_at))
            .limit(STATE_LOCK_FRAMES + STATE_UNLOCK_FRAMES + 1)
            .all()
        )
        
        if len(recent_changes) < STATE_LOCK_FRAMES:
            # å†å²è®°å½•ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­æ˜¯å¦é”å®š
            return False, 0
        
        # æ£€æŸ¥æœ€è¿‘ STATE_LOCK_FRAMES å¸§æ˜¯å¦çŠ¶æ€ä¸€è‡´
        recent_states = [change.curr_occupied for change in recent_changes[:STATE_LOCK_FRAMES]]
        if len(set(recent_states)) == 1:
            # çŠ¶æ€ä¸€è‡´ï¼Œæ£€æŸ¥æ˜¯å¦é”å®š
            state_value = recent_states[0]
            # åªæœ‰"æœ‰è½¦"çŠ¶æ€æ‰éœ€è¦é”å®šï¼ˆé˜²æ­¢é¢‘ç¹è¯¯åˆ¤ä¸º"ç¦»å¼€"ï¼‰
            # æ³¨æ„ï¼šæˆ‘ä»¬ä¹Ÿå¯ä»¥é”å®š"æ— è½¦"çŠ¶æ€ï¼ˆé˜²æ­¢é¢‘ç¹è¯¯åˆ¤ä¸º"è¿›è½¦"ï¼‰ï¼Œä½†å½“å‰ä¸»è¦é—®é¢˜æ˜¯"ç¦»å¼€"è¯¯åˆ¤
            is_locked = state_value == True  # åªæœ‰"æœ‰è½¦"çŠ¶æ€æ‰éœ€è¦é”å®š
            
            # è®¡ç®—è¿ç»­æ— è½¦å¸§æ•°ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦è¾¾åˆ°è§£é”æ¡ä»¶ï¼‰
            consecutive_empty = 0
            for change in recent_changes:
                if not change.curr_occupied:
                    consecutive_empty += 1
                else:
                    break
            
            # è®¡ç®—è¿ç»­æœ‰è½¦å¸§æ•°ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦è¾¾åˆ°é”å®šæ¡ä»¶ï¼‰
            consecutive_occupied = 0
            for change in recent_changes:
                if change.curr_occupied:
                    consecutive_occupied += 1
                else:
                    break
            
            return is_locked, consecutive_empty
        else:
            # çŠ¶æ€ä¸ä¸€è‡´ï¼Œæœªé”å®š
            return False, 0
    except Exception as e:
        print(f"[ParkingChangeWorker] æ£€æŸ¥çŠ¶æ€é”å¤±è´¥: {e}")
        return False, 0


def _determine_space_state(
    has_car_curr: bool,
    features_curr: Dict[str, Any] | None,
    has_car_prev: bool | None,
    features_prev: Dict[str, Any] | None,
    image_quality: Dict[str, Any],
    image_quality_prev: Dict[str, Any] | None = None,  # ä¸Šä¸€å¼ å›¾çš„å›¾åƒè´¨é‡ï¼ˆå¯é€‰ï¼‰
    current_time: datetime | None = None,
    prev_time: datetime | None = None,
    space_name: str = "",  # å¯é€‰ï¼šè½¦ä½åç§°ï¼Œç”¨äºæ—¥å¿—è¾“å‡º
    confidence_curr: float = 0.0,  # å½“å‰å¸§YOLOç½®ä¿¡åº¦
    detection_region_curr: Tuple[int, int, int, int] | None = None,  # å½“å‰æ£€æµ‹åŒºåŸŸ (x, y, w, h)
    detection_region_prev: Tuple[int, int, int, int] | None = None,  # ä¸Šä¸€å¸§æ£€æµ‹åŒºåŸŸ (x, y, w, h)
    space_width: int = 0,  # è½¦ä½å®½åº¦ï¼ˆç”¨äºè®¡ç®—ä½ç½®åç§»ï¼‰
) -> Tuple[bool, float, str]:
    """çŠ¶æ€å†³ç­–å¼•æ“ï¼šæ ¹æ®å½“å‰æ£€æµ‹ç»“æœã€å†å²çŠ¶æ€å’Œå›¾åƒè´¨é‡ï¼Œç¡®å®šæœ€ç»ˆçš„è½¦ä½çŠ¶æ€ã€‚
    
    å‚æ•°:
        has_car_curr: å½“å‰å¸§YOLOæ£€æµ‹ç»“æœï¼ˆæ˜¯å¦æœ‰è½¦ï¼‰
        features_curr: å½“å‰å¸§è½¦è¾†ç‰¹å¾ï¼ˆå¦‚æœæœ‰è½¦ï¼‰
        has_car_prev: ä¸Šä¸€å¸§æœ€ç»ˆçŠ¶æ€ï¼ˆcurr_occupiedï¼‰
        features_prev: ä¸Šä¸€å¸§è½¦è¾†ç‰¹å¾ï¼ˆå¦‚æœæœ‰è½¦ï¼‰
        image_quality: å½“å‰å›¾åƒè´¨é‡åˆ†æç»“æœ
        image_quality_prev: ä¸Šä¸€å¼ å›¾çš„å›¾åƒè´¨é‡åˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
        current_time: å½“å‰æˆªå›¾æ—¶é—´
        prev_time: ä¸Šä¸€å¸§æˆªå›¾æ—¶é—´
    
    è¿”å›:
        (curr_occupied, detection_confidence, change_type)
        - curr_occupied: æœ€ç»ˆçŠ¶æ€ï¼ˆç»è¿‡å¤šå¸§å¹³æ»‘+ç‰¹å¾æ¯”å¯¹åçš„å¯ä¿¡çŠ¶æ€ï¼‰
        - detection_confidence: ç»¼åˆç½®ä¿¡åº¦ï¼ˆæ£€æµ‹ç½®ä¿¡åº¦æˆ–ç‰¹å¾ç›¸ä¼¼åº¦ï¼‰
        - change_type: å˜åŒ–ç±»å‹ï¼ˆarrive/leave/Noneï¼‰
    """
    # åˆ¤æ–­æ˜¯å¦è·¨å¤©å’Œæ—¶é—´é—´éš”
    is_cross_day = False
    time_diff_seconds = None
    is_short_interval = False
    if prev_time and current_time:
        time_diff_seconds = (current_time - prev_time).total_seconds()
        is_cross_day = time_diff_seconds > 86400  # è¶…è¿‡24å°æ—¶è§†ä¸ºè·¨å¤©
        is_short_interval = time_diff_seconds < SHORT_INTERVAL_SECONDS  # æ—¶é—´é—´éš”å¾ˆçŸ­ï¼ˆå¦‚è¿ç»­æˆªå›¾ï¼‰
    
    # å¦‚æœæ²¡æœ‰æä¾›å½“å‰æ—¶é—´ï¼Œä½¿ç”¨å½“å‰UTCæ—¶é—´
    if current_time is None:
        current_time = datetime.utcnow()
    
    # è·å–å¹²æ‰°ç­‰çº§
    interference_level = image_quality.get("interference_level", "normal")
    is_high_interference = interference_level == "high"
    
    # æƒ…å†µ1: ç¬¬ä¸€å¼ å›¾ï¼ˆæ— å†å²è®°å½•ï¼‰
    if has_car_prev is None:
        if has_car_curr:
            if space_name:
                print(f"      [å†³ç­–] ç¬¬ä¸€å¼ å›¾ï¼Œæ£€æµ‹åˆ°è½¦ -> è®°å½•çŠ¶æ€ä½†ä¸æ ‡è®°ä¸ºè¿›è½¦ï¼ˆé¿å…è¯¯åˆ¤ï¼‰")
            # ç¬¬ä¸€å¼ å›¾æ£€æµ‹åˆ°è½¦ï¼Œè®°å½•çŠ¶æ€ä½†ä¸æ ‡è®°ä¸ºå˜åŒ–ï¼ˆå› ä¸ºæ— æ³•ç¡®å®šæ˜¯å¦çœŸçš„æ˜¯"è¿›è½¦"ï¼‰
            # åªæœ‰åœ¨ä¸‹ä¸€å¼ å›¾å¯¹æ¯”æ—¶æ‰èƒ½ç¡®å®šæ˜¯å¦æœ‰å˜åŒ–
            return True, 0.8, None  # ç¬¬ä¸€å¼ å›¾æ£€æµ‹åˆ°è½¦ï¼Œä¸æ ‡è®°ä¸ºè¿›è½¦ï¼Œé¿å…è¯¯åˆ¤
        else:
            if space_name:
                print(f"      [å†³ç­–] ç¬¬ä¸€å¼ å›¾ï¼Œæ— è½¦ -> æ— å˜åŒ–")
            return False, 0.0, None  # ç¬¬ä¸€å¼ å›¾æ— è½¦ï¼Œæ— å˜åŒ–
    
    # æƒ…å†µ2: å½“å‰æ— è½¦
    if not has_car_curr:
        # å¦‚æœå†å²æœ‰è½¦ï¼Œéœ€è¦åˆ¤æ–­æ˜¯çœŸå®ç¦»åœºè¿˜æ˜¯å¹²æ‰°è¯¯åˆ¤
        if has_car_prev:
            # ç¬¬ä¸‰æ­¥ï¼šçŠ¶æ€é”æœºåˆ¶ - å¦‚æœçŠ¶æ€å·²é”å®šï¼Œéœ€è¦è¿ç»­å¤šå¸§æ— è½¦æ‰å…è®¸ç¦»å¼€
            # æ³¨æ„ï¼šçŠ¶æ€é”æ£€æŸ¥éœ€è¦åœ¨è°ƒç”¨æ­¤å‡½æ•°ä¹‹å‰å®Œæˆï¼Œå› ä¸ºéœ€è¦æŸ¥è¯¢æ•°æ®åº“
            # è¿™é‡Œæˆ‘ä»¬é€šè¿‡ä¸€ä¸ªæ ‡å¿—å‚æ•°æ¥ä¼ é€’çŠ¶æ€é”ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            # å®é™…çš„çŠ¶æ€é”æ£€æŸ¥ä¼šåœ¨è°ƒç”¨æ­¤å‡½æ•°ä¹‹å‰å®Œæˆ
            #
            # è¿™é‡Œä»…ä¿ç•™â€œé«˜å¹²æ‰°æ¨¡å¼â€çš„ä¿æŠ¤ï¼Œå…¶ä½™åœºæ™¯ç›´æ¥æŒ‰ç…§æ ‡å‡†é€»è¾‘åˆ¤å®šç¦»åœºï¼Œ
            # é¿å…å› ä¸ºæš—å…‰/æ—¶é—´é—´éš”è¿‡çŸ­å¯¼è‡´çœŸå®çš„â€œé©¶ç¦»â€è¢«é•¿æœŸå‹åˆ¶ã€‚
            # é«˜å¹²æ‰°æ¨¡å¼ä¸‹ï¼Œå…è®¸å•å¸§æ¼æ£€ï¼Œç»´æŒ Occupied
            if is_high_interference and HIGH_ROBUSTNESS_MODE_ENABLED:
                if space_name:
                    print(f"      [å†³ç­–] å†å²æœ‰è½¦ï¼Œå½“å‰æ— è½¦ï¼Œä½†é«˜å¹²æ‰°æ¨¡å¼ -> ç»´æŒæœ‰è½¦çŠ¶æ€ï¼ˆä¸åˆ¤å®šç¦»åœºï¼‰")
                # ç»´æŒä¸Šä¸€å¸§çŠ¶æ€ï¼ˆOccupiedï¼‰ï¼Œä¸åˆ¤å®šä¸ºç¦»åœº
                return True, 0.5, None  # ç½®ä¿¡åº¦é™ä½ï¼Œä½†ä¸æ”¹å˜çŠ¶æ€

            # æ ‡å‡†æ¨¡å¼ï¼šåˆ¤å®šä¸ºç¦»åœºï¼ˆä¸å†å› ä¸ºæš—å…‰/æ—¶é—´çŸ­è€Œé¢å¤–æ‹¦æˆªï¼‰
            # æ³¨æ„ï¼šå¦‚æœå¯ç”¨äº†çŠ¶æ€é”ï¼Œéœ€è¦åœ¨è°ƒç”¨æ­¤å‡½æ•°ä¹‹å‰æ£€æŸ¥æ˜¯å¦é”å®šï¼›
            # å¦‚æœè¢«çŠ¶æ€é”æ‹¦æˆªï¼Œå°†ä¸ä¼šè¿›å…¥åˆ°è¿™é‡Œã€‚
            if space_name:
                print(f"      [å†³ç­–] å†å²æœ‰è½¦ï¼Œå½“å‰æ— è½¦ -> åˆ¤å®šä¸ºç¦»åœº (leave)")
            return False, 0.0, "leave"
        else:
            if space_name:
                print(f"      [å†³ç­–] å†å²æ— è½¦ï¼Œå½“å‰æ— è½¦ -> æ— å˜åŒ–")
            # å†å²æ— è½¦ï¼Œå½“å‰æ— è½¦ï¼Œæ— å˜åŒ–
            return False, 0.0, None
    
    # æƒ…å†µ3: å½“å‰æœ‰è½¦
    if has_car_curr:
        # ç¬¬ä¸€æ­¥ï¼šæœ€ä½ç½®ä¿¡åº¦è¿‡æ»¤ - YOLOç½®ä¿¡åº¦<50%æ—¶ä¸å‚ä¸"æ¢è½¦"åˆ¤æ–­
        # åœ¨å¤œé—´æˆ–æš—å…‰ç¯å¢ƒä¸‹ï¼Œè¿›ä¸€æ­¥æ”¾å®½ç½®ä¿¡åº¦è¦æ±‚ï¼ˆé™ä½åˆ°40%ï¼‰
        brightness_curr = image_quality.get("brightness", 128.0)
        is_dark = brightness_curr < 80  # æš—å…‰ç¯å¢ƒ
        min_confidence_threshold = MIN_YOLO_CONFIDENCE_FOR_CHANGE_DETECTION
        if is_dark:
            # æš—å…‰ç¯å¢ƒä¸‹ï¼Œé™ä½ç½®ä¿¡åº¦é˜ˆå€¼åˆ°40%
            min_confidence_threshold = max(0.40, MIN_YOLO_CONFIDENCE_FOR_CHANGE_DETECTION * 0.8)
            if space_name:
                print(f"      [å†³ç­–] æš—å…‰ç¯å¢ƒï¼Œé™ä½ç½®ä¿¡åº¦é˜ˆå€¼: {min_confidence_threshold:.2%} (æ ‡å‡†: {MIN_YOLO_CONFIDENCE_FOR_CHANGE_DETECTION:.2%})")
        
        if confidence_curr < min_confidence_threshold:
            if space_name:
                print(f"      [å†³ç­–] å½“å‰æœ‰è½¦ï¼Œä½†YOLOç½®ä¿¡åº¦({confidence_curr:.2%}) < æœ€ä½é˜ˆå€¼({min_confidence_threshold:.2%})")
            # å¦‚æœå†å²æœ‰è½¦ï¼Œç»´æŒçŠ¶æ€ï¼›å¦‚æœå†å²æ— è½¦ï¼Œä½†ç½®ä¿¡åº¦å¤ªä½ï¼Œä¸åˆ¤å®šä¸ºè¿›è½¦
            if has_car_prev:
                if space_name:
                    print(f"        å†å²æœ‰è½¦ -> ç»´æŒæœ‰è½¦çŠ¶æ€ï¼ˆç½®ä¿¡åº¦ä½ï¼Œä¸å‚ä¸æ¢è½¦åˆ¤æ–­ï¼‰")
                return True, confidence_curr, None  # ç»´æŒ Occupiedï¼Œä½†ç½®ä¿¡åº¦é™ä½
            else:
                if space_name:
                    print(f"        å†å²æ— è½¦ -> ç½®ä¿¡åº¦å¤ªä½ï¼Œä¸åˆ¤å®šä¸ºè¿›è½¦ï¼ˆé¿å…è¯¯åˆ¤ï¼‰")
                return False, confidence_curr, None  # ç½®ä¿¡åº¦å¤ªä½ï¼Œä¸åˆ¤å®šä¸ºè¿›è½¦
        
        # å¦‚æœå†å²æ— è½¦ï¼Œåˆ¤å®šä¸ºè¿›è½¦
        if not has_car_prev:
            confidence = 0.8 if features_curr else 0.6
            if space_name:
                print(f"      [å†³ç­–] å†å²æ— è½¦ï¼Œå½“å‰æœ‰è½¦ -> åˆ¤å®šä¸ºè¿›è½¦ (arrive), ç½®ä¿¡åº¦={confidence:.2%}")
            return True, confidence, "arrive"
        
        # å¦‚æœå†å²æœ‰è½¦ï¼Œéœ€è¦åˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€è¾†è½¦
        if features_curr and features_prev:
            # è¿›è¡Œç‰¹å¾æ¯”å¯¹
            similarity = _compare_vehicle_features(
                features_curr,
                features_prev,
                is_cross_day=is_cross_day,
            )
            
            # ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è®¡ç®—ï¼ˆè€ƒè™‘æ—¶é—´æ®µã€å›¾åƒè´¨é‡ã€æ—¶é—´é—´éš”ç­‰å› ç´ ï¼‰
            base_threshold = VEHICLE_SIMILARITY_THRESHOLD_SAME_DAY
            threshold, threshold_desc = _calculate_dynamic_similarity_threshold(
                base_threshold=base_threshold,
                current_time=current_time,
                prev_time=prev_time,
                image_quality_curr=image_quality,
                image_quality_prev=image_quality_prev,  # ä½¿ç”¨ä¸Šä¸€å¼ å›¾çš„å›¾åƒè´¨é‡
                time_diff_seconds=time_diff_seconds,
                is_short_interval=is_short_interval,
                is_cross_day=is_cross_day,
            )
            
            if space_name:
                print(f"      [å†³ç­–] å†å²æœ‰è½¦ï¼Œå½“å‰æœ‰è½¦ -> è¿›è¡Œç‰¹å¾æ¯”å¯¹")
                if time_diff_seconds is not None:
                    print(f"        æ—¶é—´é—´éš”: {time_diff_seconds:.0f} ç§’ ({time_diff_seconds/60:.1f} åˆ†é’Ÿ)")
                print(f"        ç›¸ä¼¼åº¦: {similarity:.2%}, åŠ¨æ€é˜ˆå€¼: {threshold:.2%} ({threshold_desc})")
            
            # ç¬¬äºŒæ­¥ï¼šçŠ¶æ€å»¶ç»­ä¿æŠ¤æœºåˆ¶
            # å³ä½¿ç›¸ä¼¼åº¦ç•¥ä½äºé˜ˆå€¼ï¼Œå¦‚æœæ»¡è¶³æ¡ä»¶ä»è§†ä¸ºåŒä¸€è¾†è½¦
            should_apply_protection = False
            protection_reason = ""
            
            if STATE_CONTINUATION_PROTECTION_ENABLED:
                # æ£€æŸ¥æ—¶é—´é—´éš”
                time_ok = time_diff_seconds is not None and time_diff_seconds <= STATE_CONTINUATION_TIME_THRESHOLD
                # æ£€æŸ¥ä½ç½®åç§»
                position_ok = False
                if detection_region_curr and detection_region_prev and space_width > 0:
                    position_offset = _calculate_position_offset(
                        detection_region_curr,
                        detection_region_prev,
                        space_width
                    )
                    if position_offset is not None:
                        position_ok = position_offset < STATE_CONTINUATION_POSITION_THRESHOLD
                        if space_name:
                            print(f"        ä½ç½®åç§»: {position_offset:.2%} (é˜ˆå€¼: {STATE_CONTINUATION_POSITION_THRESHOLD:.2%})")
                
                # æ£€æŸ¥ç›¸ä¼¼åº¦æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…ï¼ˆå…è®¸ä½äºé˜ˆå€¼ä¸€å®šæ¯”ä¾‹ï¼‰
                # åœ¨å¤œé—´æˆ–æš—å…‰ç¯å¢ƒä¸‹ï¼Œæ”¾å®½ç›¸ä¼¼åº¦è¦æ±‚
                brightness_curr = image_quality.get("brightness", 128.0)
                is_dark = brightness_curr < 80  # æš—å…‰ç¯å¢ƒ
                similarity_margin = STATE_CONTINUATION_SIMILARITY_MARGIN
                if is_dark:
                    # æš—å…‰ç¯å¢ƒä¸‹ï¼Œå…è®¸æ›´å¤§çš„ç›¸ä¼¼åº¦å®¹å·®ï¼ˆå¢åŠ 50%ï¼‰
                    similarity_margin = STATE_CONTINUATION_SIMILARITY_MARGIN * 1.5
                    if space_name:
                        print(f"        æš—å…‰ç¯å¢ƒï¼Œæ”¾å®½ç›¸ä¼¼åº¦å®¹å·®: {similarity_margin:.2%} (æ ‡å‡†: {STATE_CONTINUATION_SIMILARITY_MARGIN:.2%})")
                
                similarity_ok = similarity >= (threshold - similarity_margin)
                
                # å¦‚æœæ»¡è¶³æ—¶é—´å’Œä½ç½®æ¡ä»¶ï¼Œå³ä½¿ç›¸ä¼¼åº¦ç•¥ä½ï¼Œä¹Ÿç»™äºˆæ›´å¤§çš„å®¹å·®ï¼ˆå¤œé—´ç¯å¢ƒä¸‹ï¼‰
                if time_ok and position_ok:
                    if similarity_ok:
                        should_apply_protection = True
                        protection_reason = f"æ—¶é—´é—´éš”â‰¤{STATE_CONTINUATION_TIME_THRESHOLD}ç§’ä¸”ä½ç½®åç§»<{STATE_CONTINUATION_POSITION_THRESHOLD:.0%}"
                    elif is_dark and similarity >= (threshold - similarity_margin * 1.5):
                        # å¤œé—´ç¯å¢ƒä¸‹ï¼Œå¦‚æœç›¸ä¼¼åº¦åœ¨æ›´å¤§å®¹å·®èŒƒå›´å†…ï¼Œä¹Ÿç»™äºˆä¿æŠ¤
                        should_apply_protection = True
                        protection_reason = f"æ—¶é—´é—´éš”â‰¤{STATE_CONTINUATION_TIME_THRESHOLD}ç§’ä¸”ä½ç½®åç§»<{STATE_CONTINUATION_POSITION_THRESHOLD:.0%}ï¼ˆå¤œé—´æ”¾å®½ï¼‰"
            
            if similarity >= threshold:
                # åŒä¸€è¾†è½¦ï¼ŒçŠ¶æ€å»¶ç»­
                if space_name:
                    print(f"        ç›¸ä¼¼åº¦ >= é˜ˆå€¼ -> åŒä¸€è¾†è½¦ï¼ŒçŠ¶æ€å»¶ç»­ï¼ˆæ— å˜åŒ–ï¼‰")
                return True, similarity, None
            elif should_apply_protection:
                # çŠ¶æ€å»¶ç»­ä¿æŠ¤ï¼šç›¸ä¼¼åº¦ç•¥ä½äºé˜ˆå€¼ï¼Œä½†æ»¡è¶³ä¿æŠ¤æ¡ä»¶
                if space_name:
                    print(f"        ç›¸ä¼¼åº¦ç•¥ä½äºé˜ˆå€¼ï¼Œä½†æ»¡è¶³çŠ¶æ€å»¶ç»­ä¿æŠ¤æ¡ä»¶ ({protection_reason}) -> è§†ä¸ºåŒä¸€è¾†è½¦ï¼ŒçŠ¶æ€å»¶ç»­")
                return True, similarity, None
            else:
                # ä¸åŒè½¦ï¼Œæ¢è½¦è¡Œä¸º
                # æ³¨æ„ï¼šè™½ç„¶çŠ¶æ€éƒ½æ˜¯"æœ‰è½¦"ï¼Œä½†è¿™æ˜¯æ¢è½¦ï¼Œä¸æ˜¯"è¿›è½¦"
                # ä¸ºäº†åŒºåˆ†"æ¢è½¦"å’ŒçœŸæ­£çš„"è¿›è½¦"ï¼Œè¿™é‡Œæ ‡è®°ä¸º Noneï¼Œé¿å…è¯¯åˆ¤
                if space_name:
                    print(f"        ç›¸ä¼¼åº¦ < é˜ˆå€¼ -> ä¸åŒè½¦è¾†ï¼Œåˆ¤å®šä¸ºæ¢è½¦ï¼ˆä½†ä¸æ ‡è®°ä¸ºè¿›è½¦ï¼Œé¿å…è¯¯åˆ¤ï¼‰")
                # æ¢è½¦æƒ…å†µï¼šçŠ¶æ€éƒ½æ˜¯"æœ‰è½¦"ï¼Œä¸æ ‡è®°ä¸º"è¿›è½¦"ï¼Œé¿å…ç”¨æˆ·çœ‹åˆ°"æœ‰è½¦ â†’ æœ‰è½¦"ä½†æ˜¾ç¤º"è¿›è½¦"çš„å›°æƒ‘
                return True, similarity, None
        else:
            # ç‰¹å¾ç¼ºå¤±ï¼Œæ— æ³•æ¯”å¯¹ï¼Œä¿å®ˆå¤„ç†
            # å¦‚æœæœ‰å†å²çŠ¶æ€ï¼Œç»´æŒçŠ¶æ€ï¼›å¦åˆ™ä½¿ç”¨å½“å‰æ£€æµ‹ç»“æœ
            if has_car_prev:
                if space_name:
                    print(f"      [å†³ç­–] å†å²æœ‰è½¦ï¼Œå½“å‰æœ‰è½¦ï¼Œä½†ç‰¹å¾ç¼ºå¤± -> ç»´æŒæœ‰è½¦çŠ¶æ€ï¼Œç½®ä¿¡åº¦é™ä½")
                return True, 0.6, None  # ç»´æŒ Occupiedï¼Œä½†ç½®ä¿¡åº¦é™ä½
            else:
                if space_name:
                    print(f"      [å†³ç­–] å†å²æ— è½¦ï¼Œå½“å‰æœ‰è½¦ï¼ˆç‰¹å¾ç¼ºå¤±ï¼‰-> åˆ¤å®šä¸ºè¿›è½¦ (arrive)")
                return True, 0.7, "arrive"
    
    # é»˜è®¤æƒ…å†µï¼ˆç†è®ºä¸Šä¸ä¼šåˆ°è¾¾ï¼‰
    return False, 0.0, None


def process_pending_screenshots(batch_size: int = 10) -> int:
    """å¤„ç†ä¸€æ‰¹å¾…æ£€æµ‹æˆªå›¾ï¼Œè¿”å›æœ¬æ¬¡å¤„ç†çš„æ•°é‡ã€‚"""
    with SessionLocal() as db:
        shots: List[Screenshot] = (
            db.query(Screenshot)
            .filter(Screenshot.yolo_status == "pending")
            .order_by(Screenshot.id.asc())
            .limit(batch_size)
            .all()
        )
        if not shots:
            return 0

        processed = 0
        for shot in shots:
            try:
                print(f"\n{'='*80}")
                print(f"[ParkingChangeWorker] å¼€å§‹å¤„ç†æˆªå›¾ ID={shot.id}, æ–‡ä»¶è·¯å¾„={shot.file_path}")
                print(f"{'='*80}")
                
                shot.yolo_status = "processing"
                shot.yolo_last_error = None
                db.flush()

                task = db.query(Task).filter(Task.id == shot.task_id).first()
                if not task:
                    print(f"[ParkingChangeWorker] âŒ æˆªå›¾ ID={shot.id} å…³è”çš„ Task (ID={shot.task_id}) ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                    shot.yolo_status = "failed"
                    shot.yolo_last_error = "å…³è” Task ä¸å­˜åœ¨"
                    continue

                print(f"[ParkingChangeWorker] ä»»åŠ¡ä¿¡æ¯: ID={task.id}, IP={task.ip}, é€šé“={task.channel}, æ—¥æœŸ={task.date}")

                channel_cfg, spaces = _get_channel_config_and_spaces(db, task)
                if not channel_cfg or not spaces:
                    print(f"[ParkingChangeWorker] âš ï¸  æˆªå›¾ ID={shot.id} æ²¡æœ‰é€šé“é…ç½®æˆ–è½¦ä½é…ç½®")
                    print(f"   é€šé“é…ç½®: {'å­˜åœ¨' if channel_cfg else 'ä¸å­˜åœ¨'}")
                    print(f"   è½¦ä½æ•°é‡: {len(spaces) if spaces else 0}")
                    # æ²¡æœ‰é€šé“/è½¦ä½é…ç½®ï¼Œç›´æ¥æ ‡è®° doneï¼Œä½†ä¸äº§ç”Ÿå˜åŒ–è®°å½•
                    shot.yolo_status = "done"
                    continue

                print(f"[ParkingChangeWorker] âœ“ é€šé“é…ç½®: ID={channel_cfg.id}, é€šé“={channel_cfg.channel_code}")
                print(f"[ParkingChangeWorker] âœ“ è½¦ä½é…ç½®: å…± {len(spaces)} ä¸ªè½¦ä½")
                for space in spaces:
                    print(f"   - è½¦ä½ {space.space_name} (ID={space.id}): åæ ‡ ({space.bbox_x1},{space.bbox_y1}) -> ({space.bbox_x2},{space.bbox_y2})")

                img_path = Path(shot.file_path)
                if not img_path.is_absolute():
                    img_path = SCREENSHOT_BASE / img_path
                if not img_path.exists():
                    print(f"[ParkingChangeWorker] âŒ æˆªå›¾ ID={shot.id} å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                    shot.yolo_status = "failed"
                    shot.yolo_last_error = f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}"
                    continue

                print(f"[ParkingChangeWorker] âœ“ å›¾ç‰‡æ–‡ä»¶å­˜åœ¨: {img_path}")

                # å…ˆåˆ†æå›¾åƒè´¨é‡ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´æ£€æµ‹å‚æ•°å’Œå¹²æ‰°åˆ¤å®šï¼‰
                print(f"[ParkingChangeWorker] ========== å›¾åƒè´¨é‡åˆ†æ ==========")
                current_screenshot_time = shot.created_at if hasattr(shot, 'created_at') and shot.created_at else None
                image_quality = _analyze_image_quality(img_path, image_time=current_screenshot_time)
                
                # æå–è´¨é‡ä¿¡æ¯
                image_brightness = image_quality.get('brightness', 128.0)
                clarity = image_quality.get('clarity', 100.0)
                interference_level = image_quality.get('interference_level', 'normal')
                weather = image_quality.get('weather', 'sunny')
                day_night = image_quality.get('day_night', 'day')
                quality_description = image_quality.get('quality_description', '')
                
                # å¤©æ°”å’Œæ—¶æ®µåç§°æ˜ å°„
                weather_names = {"rainy": "é›¨å¤©", "foggy": "é›¾å¤©", "cloudy": "é˜´å¤©", "sunny": "æ™´å¤©"}
                day_night_names = {"day": "ç™½å¤©", "night": "æ™šä¸Š"}
                interference_names = {"high": "é«˜", "normal": "ä¸­", "low": "ä½"}
                
                weather_name = weather_names.get(weather, "æœªçŸ¥")
                day_night_name = day_night_names.get(day_night, "æœªçŸ¥")
                interference_name = interference_names.get(interference_level, "æœªçŸ¥")
                
                # è¯¦ç»†æ—¥å¿—è¾“å‡º
                print(f"[ParkingChangeWorker] ğŸ“¸ å›¾åƒåŸºæœ¬ä¿¡æ¯:")
                print(f"   æ–‡ä»¶è·¯å¾„: {img_path.name}")
                if current_screenshot_time:
                    print(f"   æˆªå›¾æ—¶é—´: {current_screenshot_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    print(f"   æ—¶æ®µè¯†åˆ«: {day_night_name} (åŸºäºæ—¶é—´: {current_screenshot_time.hour}æ—¶)")
                else:
                    print(f"   æ—¶æ®µè¯†åˆ«: {day_night_name} (åŸºäºäº®åº¦: {image_brightness:.1f})")
                
                print(f"[ParkingChangeWorker] ğŸ“Š å›¾åƒè´¨é‡æŒ‡æ ‡:")
                print(f"   å¹³å‡äº®åº¦: {image_brightness:.2f} (èŒƒå›´: 0-255)")
                print(f"   æ¸…æ™°åº¦: {clarity:.2f} (Laplacianæ–¹å·®)")
                print(f"   å¹²æ‰°ç­‰çº§: {interference_name} ({interference_level})")
                print(f"   å¤©æ°”æ¡ä»¶: {weather_name}")
                
                print(f"[ParkingChangeWorker] ğŸ” è´¨é‡è¯„ä¼°:")
                print(f"   {quality_description}")
                
                # é—®é¢˜è­¦å‘Š
                warnings = []
                if image_brightness < BRIGHTNESS_LOW_THRESHOLD:
                    warnings.append(f"âš ï¸ æ¬ æ›ï¼ˆäº®åº¦={image_brightness:.1f} < {BRIGHTNESS_LOW_THRESHOLD}ï¼‰")
                elif image_brightness > BRIGHTNESS_HIGH_THRESHOLD:
                    warnings.append(f"âš ï¸ è¿‡æ›ï¼ˆäº®åº¦={image_brightness:.1f} > {BRIGHTNESS_HIGH_THRESHOLD}ï¼‰")
                
                if clarity < CLARITY_THRESHOLD:
                    warnings.append(f"âš ï¸ æ¨¡ç³Šï¼ˆæ¸…æ™°åº¦={clarity:.1f} < {CLARITY_THRESHOLD}ï¼‰")
                
                if image_brightness < 120:
                    warnings.append(f"âš ï¸ æš—å…‰ç¯å¢ƒï¼ˆäº®åº¦={image_brightness:.1f}ï¼‰ï¼Œå°†å¯ç”¨å¤œé—´å¢å¼ºå’ŒåŠ¨æ€é˜ˆå€¼è°ƒæ•´")
                
                if weather in ("rainy", "foggy"):
                    warnings.append(f"âš ï¸ æ¶åŠ£å¤©æ°”ï¼ˆ{weather_name}ï¼‰ï¼Œå°†æ”¾å®½ç›¸ä¼¼åº¦é˜ˆå€¼")
                
                if warnings:
                    print(f"[ParkingChangeWorker] âš ï¸ æ£€æµ‹åˆ°ä»¥ä¸‹é—®é¢˜:")
                    for warning in warnings:
                        print(f"   {warning}")
                else:
                    print(f"[ParkingChangeWorker] âœ… å›¾åƒè´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹æ®Šå¤„ç†")
                
                print(f"[ParkingChangeWorker] ======================================")

                # å¯¹æ¯ä¸ªè½¦ä½åæ ‡åŒºåŸŸå•ç‹¬è¿›è¡Œ YOLO æ£€æµ‹ï¼ˆåŒ…å«ç‰¹å¾æå–ï¼‰
                # è¿™æ ·åªæ£€æµ‹è½¦ä½èŒƒå›´å†…çš„è½¦è¾†ï¼Œæé«˜ç²¾åº¦å’Œæ€§èƒ½
                # å¦‚æœåŒºåŸŸå¤ªå°ï¼Œä¼šå›é€€åˆ°ä½¿ç”¨è·Ÿè¸ªåŒºåŸŸï¼ˆtrack_spaceï¼‰è¿›è¡Œæ£€æµ‹
                print(f"[ParkingChangeWorker] å¼€å§‹ YOLO æ£€æµ‹...")
                track_space_str = channel_cfg.track_space if channel_cfg else None
                space_occupied_map, detection_regions, confidence_map, features_map = _detect_space_occupancy(
                    img_path, spaces, track_space_str, extract_features=True, image_brightness=image_brightness
                )
                
                # è¾“å‡ºæ£€æµ‹ç»“æœ
                print(f"[ParkingChangeWorker] YOLO æ£€æµ‹å®Œæˆï¼Œç»“æœå¦‚ä¸‹:")
                for space in spaces:
                    occupied = space_occupied_map.get(space.id, False)
                    confidence = confidence_map.get(space.id, 0.0)
                    has_features = space.id in features_map and features_map[space.id] is not None
                    print(f"   è½¦ä½ {space.space_name}: {'æœ‰è½¦' if occupied else 'æ— è½¦'} (ç½®ä¿¡åº¦: {confidence:.2%}) {'[å·²æå–ç‰¹å¾]' if has_features else '[æ— ç‰¹å¾]'}")
                
                # åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶ç»¿è‰²çº¿æ ‡è®°å®é™…æ£€æµ‹çš„åŒºåŸŸ
                try:
                    _draw_detection_regions(img_path, spaces, detection_regions)
                except Exception as e:
                    # ç»˜åˆ¶å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                    print(f"[ParkingChangeWorker] ç»˜åˆ¶æ£€æµ‹åŒºåŸŸå¤±è´¥ï¼ˆä¸å½±å“æ£€æµ‹ï¼‰: {e}")

                changes: List[ParkingChange] = []
                changed_count = 0  # æœ¬å¼ å›¾ä¸­å®é™…â€œæœ‰å˜åŒ–â€çš„è½¦ä½æ•°é‡ï¼ˆarrive/leaveï¼‰
                # current_screenshot_time å·²åœ¨å›¾åƒè´¨é‡åˆ†ææ—¶å®šä¹‰ï¼ˆç¬¬1072è¡Œï¼‰ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨
                
                print(f"[ParkingChangeWorker] å¼€å§‹åˆ†æè½¦ä½çŠ¶æ€å˜åŒ–...")
                if current_screenshot_time:
                    print(f"   å½“å‰æˆªå›¾æ—¶é—´: {current_screenshot_time.strftime('%Y-%m-%d %H:%M:%S')}")
                else:
                    print(f"   å½“å‰æˆªå›¾æ—¶é—´: æœªçŸ¥")
                
                for space in spaces:
                    print(f"\n  [è½¦ä½ {space.space_name}] å¼€å§‹åˆ†æ...")
                    curr_occupied = space_occupied_map.get(space.id, False)
                    curr_confidence = confidence_map.get(space.id, 0.0)
                    
                    # å»¶è¿Ÿç¡®è®¤æœºåˆ¶ï¼šéªŒè¯å¹¶æ’¤é”€è¯¯åˆ¤çš„leaveäº‹ä»¶
                    # å¦‚æœä¸Šä¸€å¼ æˆªå›¾ï¼ˆçº¦10åˆ†é’Ÿå‰ï¼‰åˆ¤å®šä¸º"ç¦»å¼€"ï¼Œä½†å½“å‰æˆªå›¾æ˜¾ç¤ºæœ‰è½¦ï¼Œåˆ™æ’¤é”€ä¹‹å‰çš„åˆ¤å®š
                    if current_screenshot_time:
                        revoked = _verify_and_revoke_false_leave(
                            db,
                            channel_cfg.id,
                            space.id,
                            space.space_name,
                            shot.id,
                            current_screenshot_time,
                            curr_occupied,
                        )
                        if revoked:
                            # å¦‚æœæ’¤é”€äº†è¯¯åˆ¤ï¼Œéœ€è¦åˆ·æ–°æ•°æ®åº“çŠ¶æ€
                            db.flush()
                    
                    # è·å–åŒä¸€é€šé“ä¸‹ä¸Šä¸€å¼ æˆªå›¾ä¸­è¯¥è½¦ä½çš„çŠ¶æ€å’Œç‰¹å¾ï¼ˆå¸¦æ—¶é—´é—´éš”æ£€æŸ¥ï¼‰
                    # æˆªå›¾é—´éš”10åˆ†é’Ÿï¼Œæœ€å¤§å…è®¸é—´éš”15åˆ†é’Ÿï¼ˆå…è®¸ä¸€å®šçš„å®¹å·®ï¼‰
                    prev_occupied, prev_screenshot_id, prev_features = _get_prev_occupied_for_channel(
                        db, 
                        channel_cfg.id, 
                        space.id, 
                        shot.id,
                        current_screenshot_time,
                        task.id,
                        max_time_gap_seconds=900  # 15åˆ†é’Ÿï¼ˆæˆªå›¾é—´éš”10åˆ†é’Ÿï¼Œå…è®¸15åˆ†é’Ÿå®¹å·®ï¼‰
                    )
                    
                    # è·å–ä¸Šä¸€å¸§æˆªå›¾æ—¶é—´å’Œå›¾åƒè´¨é‡ï¼ˆç”¨äºè·¨å¤©åˆ¤æ–­å’ŒåŠ¨æ€é˜ˆå€¼è®¡ç®—ï¼‰
                    prev_time = None
                    prev_image_quality = None
                    if prev_screenshot_id:
                        prev_screenshot = db.query(Screenshot).filter(Screenshot.id == prev_screenshot_id).first()
                        if prev_screenshot and prev_screenshot.created_at:
                            prev_time = prev_screenshot.created_at
                            # åˆ†æä¸Šä¸€å¼ æˆªå›¾çš„å›¾åƒè´¨é‡ï¼ˆç”¨äºåŠ¨æ€é˜ˆå€¼è°ƒæ•´ï¼‰
                            if prev_screenshot.file_path:
                                prev_img_path = Path(prev_screenshot.file_path)
                                if not prev_img_path.is_absolute():
                                    prev_img_path = SCREENSHOT_BASE / prev_img_path
                                if prev_img_path.exists():
                                    try:
                                        prev_screenshot_time = prev_screenshot.created_at if prev_screenshot and prev_screenshot.created_at else None
                                        prev_image_quality = _analyze_image_quality(prev_img_path, image_time=prev_screenshot_time)
                                    except Exception as e:
                                        print(f"[ParkingChangeWorker] åˆ†æä¸Šä¸€å¼ æˆªå›¾å›¾åƒè´¨é‡å¤±è´¥: {e}")
                    
                    # è·å–å½“å‰å¸§çš„æ£€æµ‹ç»“æœå’Œç‰¹å¾
                    has_car_curr = space_occupied_map.get(space.id, False)
                    features_curr = features_map.get(space.id)
                    curr_confidence = confidence_map.get(space.id, 0.0)
                    detection_region_curr = detection_regions.get(space.id)
                    
                    # è·å–ä¸Šä¸€å¸§çš„æ£€æµ‹åŒºåŸŸ
                    # æ³¨æ„ï¼šç”±äºæ•°æ®åº“ä¸­æ²¡æœ‰ä¿å­˜æ£€æµ‹åŒºåŸŸï¼Œæˆ‘ä»¬ä½¿ç”¨æ™ºèƒ½ä¼°ç®—æ–¹æ³•
                    # ç­–ç•¥ï¼šå¦‚æœå½“å‰å¸§æœ‰è½¦ï¼Œä½¿ç”¨å½“å‰æ£€æµ‹åŒºåŸŸä½œä¸ºä¸Šä¸€å¸§çš„å‚è€ƒï¼ˆå‡è®¾è½¦è¾†ä½ç½®å˜åŒ–ä¸å¤§ï¼‰
                    # å¦‚æœå½“å‰å¸§æ— è½¦ä½†ä¸Šä¸€å¸§æœ‰è½¦ï¼Œä½¿ç”¨è½¦ä½åæ ‡ä½œä¸ºå‚è€ƒ
                    detection_region_prev = None
                    if prev_occupied and prev_screenshot_id:
                        if detection_region_curr:
                            # ä¼˜å…ˆä½¿ç”¨å½“å‰å¸§çš„æ£€æµ‹åŒºåŸŸä½œä¸ºå‚è€ƒï¼ˆæ›´å‡†ç¡®ï¼Œå› ä¸ºè½¦è¾†ä½ç½®å˜åŒ–é€šå¸¸ä¸å¤§ï¼‰
                            detection_region_prev = detection_region_curr
                        else:
                            # å¦‚æœå½“å‰å¸§æ— è½¦ï¼Œä½¿ç”¨è½¦ä½åæ ‡ä½œä¸ºå‚è€ƒ
                            detection_region_prev = (
                                int(space.bbox_x1),
                                int(space.bbox_y1),
                                max(1, int(space.bbox_x2)),
                                max(1, int(space.bbox_y2)),
                            )
                    
                    # è·å–è½¦ä½å®½åº¦ï¼ˆç”¨äºè®¡ç®—ä½ç½®åç§»ï¼‰
                    space_width = max(1, int(space.bbox_x2))  # bbox_x2 æ˜¯å®½åº¦
                    
                    print(f"    å½“å‰æ£€æµ‹: {'æœ‰è½¦' if has_car_curr else 'æ— è½¦'} (ç½®ä¿¡åº¦: {curr_confidence:.2%})")
                    if prev_screenshot_id:
                        print(f"    ä¸Šä¸€å¼ çŠ¶æ€: {'æœ‰è½¦' if prev_occupied else 'æ— è½¦'} (æˆªå›¾ID: {prev_screenshot_id})")
                        if prev_time:
                            time_gap = (current_screenshot_time - prev_time).total_seconds() if current_screenshot_time and prev_time else None
                            if time_gap:
                                print(f"    æ—¶é—´é—´éš”: {time_gap:.0f} ç§’ ({time_gap/60:.1f} åˆ†é’Ÿ)")
                        if prev_features:
                            print(f"    ä¸Šä¸€å¼ ç‰¹å¾: å·²æå–")
                        else:
                            print(f"    ä¸Šä¸€å¼ ç‰¹å¾: æ— ")
                    else:
                        print(f"    ä¸Šä¸€å¼ çŠ¶æ€: æ— å†å²è®°å½•ï¼ˆç¬¬ä¸€å¼ å›¾ï¼‰")
                    
                    # ç¬¬ä¸‰æ­¥ï¼šçŠ¶æ€é”æ£€æŸ¥ï¼ˆåœ¨è°ƒç”¨çŠ¶æ€å†³ç­–å¼•æ“ä¹‹å‰ï¼‰
                    is_state_locked = False
                    consecutive_empty_frames = 0
                    if STATE_LOCK_ENABLED and current_screenshot_time:
                        is_state_locked, consecutive_empty_frames = _check_state_lock(
                            db,
                            channel_cfg.id,
                            space.id,
                            current_screenshot_time,
                            max_time_gap_seconds=900,  # 15åˆ†é’Ÿ
                        )
                        if is_state_locked:
                            print(f"    [çŠ¶æ€é”] çŠ¶æ€å·²é”å®šï¼ˆè¿ç»­{STATE_LOCK_FRAMES}å¸§ä¸å˜ï¼‰")
                            if not has_car_curr:
                                print(f"    [çŠ¶æ€é”] å½“å‰æ— è½¦ï¼Œè¿ç»­æ— è½¦å¸§æ•°: {consecutive_empty_frames}/{STATE_UNLOCK_FRAMES}")
                                if consecutive_empty_frames < STATE_UNLOCK_FRAMES:
                                    print(f"    [çŠ¶æ€é”] æœªè¾¾åˆ°è§£é”æ¡ä»¶ï¼ˆéœ€è¦è¿ç»­{STATE_UNLOCK_FRAMES}å¸§æ— è½¦ï¼‰ï¼Œç»´æŒæœ‰è½¦çŠ¶æ€")
                                    # çŠ¶æ€å·²é”å®šä¸”æœªè¾¾åˆ°è§£é”æ¡ä»¶ï¼Œç»´æŒæœ‰è½¦çŠ¶æ€
                                    curr_occupied_final = True
                                    detection_confidence_final = 0.5
                                    change_type = None
                                    # è·³è¿‡çŠ¶æ€å†³ç­–å¼•æ“ï¼Œç›´æ¥ä½¿ç”¨é”å®šçŠ¶æ€
                                    print(f"    [çŠ¶æ€é”] è·³è¿‡çŠ¶æ€å†³ç­–ï¼Œç»´æŒé”å®šçŠ¶æ€")
                                else:
                                    print(f"    [çŠ¶æ€é”] å·²è¾¾åˆ°è§£é”æ¡ä»¶ï¼Œå…è®¸ç¦»å¼€")
                                    # å·²è¾¾åˆ°è§£é”æ¡ä»¶ï¼Œç»§ç»­æ­£å¸¸å†³ç­–æµç¨‹
                                    is_state_locked = False
                            else:
                                # å½“å‰æœ‰è½¦ï¼ŒçŠ¶æ€é”ä¸å½±å“å†³ç­–
                                is_state_locked = False
                    
                    # è°ƒç”¨çŠ¶æ€å†³ç­–å¼•æ“ï¼ˆå¦‚æœçŠ¶æ€é”æœªæ‹¦æˆªï¼‰
                    if not (is_state_locked and not has_car_curr and consecutive_empty_frames < STATE_UNLOCK_FRAMES):
                        print(f"    è°ƒç”¨çŠ¶æ€å†³ç­–å¼•æ“...")
                        curr_occupied_final, detection_confidence_final, change_type = _determine_space_state(
                            has_car_curr=has_car_curr,
                            features_curr=features_curr,
                            has_car_prev=prev_occupied,
                            features_prev=prev_features,
                            image_quality=image_quality,
                            image_quality_prev=prev_image_quality,  # ä¼ é€’ä¸Šä¸€å¼ å›¾çš„å›¾åƒè´¨é‡
                            current_time=current_screenshot_time or datetime.utcnow(),
                            prev_time=prev_time,
                            space_name=space.space_name,  # ä¼ é€’è½¦ä½åç§°ç”¨äºæ—¥å¿—
                            confidence_curr=curr_confidence,  # ä¼ é€’å½“å‰å¸§YOLOç½®ä¿¡åº¦
                            detection_region_curr=detection_region_curr,  # ä¼ é€’å½“å‰æ£€æµ‹åŒºåŸŸ
                            detection_region_prev=detection_region_prev,  # ä¼ é€’ä¸Šä¸€å¸§æ£€æµ‹åŒºåŸŸ
                            space_width=space_width,  # ä¼ é€’è½¦ä½å®½åº¦
                        )
                    
                    print(f"    å†³ç­–ç»“æœ: æœ€ç»ˆçŠ¶æ€={'æœ‰è½¦' if curr_occupied_final else 'æ— è½¦'}, ç½®ä¿¡åº¦={detection_confidence_final:.2%}, å˜åŒ–ç±»å‹={change_type or 'æ— å˜åŒ–'}")
                    
                    # ä½¿ç”¨å†³ç­–å¼•æ“çš„ç»“æœï¼ˆå·²ç»åŒ…å«äº†å¤šå¸§ç¡®è®¤ã€ç‰¹å¾æ¯”å¯¹å’Œå¹²æ‰°è‡ªé€‚åº”é€»è¾‘ï¼‰
                    curr_occupied = curr_occupied_final
                    curr_confidence = detection_confidence_final
                    # change_type å·²ç”±å†³ç­–å¼•æ“ç¡®å®š
                    
                    # è®°å½•æ‰€æœ‰è½¦ä½çŠ¶æ€ï¼ˆæ— è®ºæ˜¯å¦æœ‰å˜åŒ–ï¼‰ï¼Œç”¨äºåç»­å¯¹æ¯”
                    # change_type ä¸º None è¡¨ç¤º"æ— å˜åŒ–"
                    change = ParkingChange(
                        task_id=task.id,
                        screenshot_id=shot.id,
                        channel_config_id=channel_cfg.id,
                        space_id=space.id,
                        space_name=space.space_name,
                        prev_occupied=prev_occupied,  # None è¡¨ç¤º"æœªçŸ¥"ï¼ˆç¬¬ä¸€å¼ å›¾ï¼‰
                        curr_occupied=curr_occupied,  # ç»è¿‡çŠ¶æ€å†³ç­–å¼•æ“å¤„ç†åçš„æœ€ç»ˆçŠ¶æ€
                        change_type=change_type,  # ç”±å†³ç­–å¼•æ“ç¡®å®šï¼ˆarrive/leave/Noneï¼‰
                        detection_confidence=curr_confidence if curr_confidence > 0 else None,  # ç»¼åˆç½®ä¿¡åº¦ï¼ˆæ£€æµ‹ç½®ä¿¡åº¦æˆ–ç‰¹å¾ç›¸ä¼¼åº¦ï¼‰
                        vehicle_features=features_curr,  # ä¿å­˜å½“å‰å¸§çš„è½¦è¾†ç‰¹å¾ï¼ˆç”¨äºåç»­æ¯”å¯¹ï¼‰
                    )
                    changes.append(change)
                    db.add(change)

                    # ç»Ÿè®¡æœ‰å˜åŒ–çš„è½¦ä½æ•°é‡ï¼ˆåªç»Ÿè®¡ arrive/leaveï¼‰
                    if change_type in ("arrive", "leave"):
                        changed_count += 1
                        print(f"    âœ“ æ£€æµ‹åˆ°å˜åŒ–: {change_type}")

                print(f"\n[ParkingChangeWorker] è½¦ä½çŠ¶æ€åˆ†æå®Œæˆ:")
                print(f"   æ€»è½¦ä½æ•°: {len(spaces)}")
                print(f"   æœ‰å˜åŒ–è½¦ä½: {changed_count} ä¸ª")
                print(f"   ç”Ÿæˆå˜åŒ–è®°å½•: {len(changes)} æ¡")

                # åªæœ‰åœ¨â€œè‡³å°‘æœ‰ä¸€ä¸ªè½¦ä½å‘ç”Ÿå˜åŒ–â€æ—¶ï¼Œæ‰ç”Ÿæˆå¿«ç…§è®°å½•ï¼Œ
                # è¿™æ ·è½¦ä½å˜åŒ–åˆ—è¡¨é¡µé¢åªå±•ç¤ºâ€œæœ‰å˜åŒ–â€çš„æˆªå›¾ã€‚
                if changes and changed_count > 0:
                    snapshot = ParkingChangeSnapshot(
                        task_id=task.id,
                        screenshot_id=shot.id,
                        channel_config_id=channel_cfg.id,
                        ip=task.ip,
                        channel_code=task.channel,
                        parking_name=channel_cfg.nvr_config.parking_name if channel_cfg.nvr_config else None,
                        change_count=changed_count,
                    )
                    db.add(snapshot)
                    print(f"  âœ“ å·²åˆ›å»ºå¿«ç…§è®°å½• (parking_change_snapshots), å˜åŒ–æ•°é‡: {changed_count}")
                else:
                    print(f"  âš ï¸  æ— è½¦ä½å˜åŒ–ï¼Œä¸åˆ›å»ºå¿«ç…§è®°å½•ï¼ˆä½†å·²ä¿å­˜æ‰€æœ‰è½¦ä½çš„çŠ¶æ€è®°å½•åˆ° parking_changes è¡¨ï¼‰")

                shot.yolo_status = "done"
                processed += 1
                print(f"[ParkingChangeWorker] âœ“ æˆªå›¾ ID={shot.id} å¤„ç†å®Œæˆ\n")
            except Exception as e:  # noqa: BLE001
                print(f"[ParkingChangeWorker] âŒ å¤„ç†æˆªå›¾ ID={shot.id} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                shot.yolo_status = "failed"
                shot.yolo_last_error = str(e)
            finally:
                db.flush()

        db.commit()
        if processed > 0:
            print(f"[ParkingChangeWorker] æœ¬æ¬¡æ‰¹æ¬¡å¤„ç†å®Œæˆ: å…±å¤„ç† {processed} å¼ æˆªå›¾\n")
        return processed


def main_loop(interval_seconds: int = 5, batch_size: int = 10) -> None:
    """ç®€å•çš„è½®è¯¢ä¸»å¾ªç¯ï¼Œå¯ç”±ç‹¬ç«‹è¿›ç¨‹å¯åŠ¨ã€‚"""
    print("[ParkingChangeWorker] å¯åŠ¨ Worker...")
    
    # å¯åŠ¨æ—¶é¢„åŠ è½½æ¨¡å‹ï¼ˆä¼šè§¦å‘è‡ªåŠ¨ä¸‹è½½ï¼‰
    print("[ParkingChangeWorker] æ­£åœ¨é¢„åŠ è½½ YOLO æ¨¡å‹ï¼ˆå¦‚æœæ¨¡å‹ä¸å­˜åœ¨ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰...")
    if preload_model():
        print("[ParkingChangeWorker] âœ“ YOLO æ¨¡å‹åŠ è½½å®Œæˆï¼ŒWorker å·²å°±ç»ª")
    else:
        print("[ParkingChangeWorker] âœ— æ¨¡å‹åŠ è½½å¤±è´¥ï¼ŒWorker å°†ç»§ç»­è¿è¡Œï¼Œä½†æ— æ³•å¤„ç†æˆªå›¾ï¼Œç›´åˆ°æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    print("[ParkingChangeWorker] å¼€å§‹è½®è¯¢å¾…å¤„ç†çš„æˆªå›¾...")
    while True:
        count = process_pending_screenshots(batch_size=batch_size)
        if count > 0:
            print(f"[ParkingChangeWorker] æœ¬æ¬¡å¤„ç†äº† {count} å¼ æˆªå›¾")
        time.sleep(interval_seconds)


if __name__ == "__main__":
    main_loop()

